{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Version of TensorFlow and Access to GPU\n",
    "This will check to make sure you have the correct version of TensorFlow and access to a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo List\n",
    "- Add several dense layers after convolutional layers\n",
    "- Play with learning rate and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.1.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_dir = 'DataSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: DataSet/2018-07-13_18-39-56_0.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-43-51_0.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-46-04_1.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-47-58_2.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-49-54_3.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-52-16_4.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-54-29_5.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-56-38_6.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-58-30_7.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-00-21_8.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-02-36_9.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-04-42_10.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-06-38_11.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-08-49_12.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-10-48_13.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-12-43_14.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-14-54_15.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-16-54_16.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-19-01_17.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-20-48_18.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-22-54_19.pkl, DataSet Length: 500\n",
      "File: DataSet/data_07-08-18.pkl, DataSet Length: 7150\n",
      "File: DataSet/data_07-10-18_work.pkl, DataSet Length: 8700\n",
      "File: DataSet/data_07-13-18.pkl, DataSet Length: 5400\n",
      "Total Length: 31750\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith(\".pkl\"): \n",
    "        df = pd.read_pickle(os.path.join(dataset_dir, filename))\n",
    "        \n",
    "        if count == 0:\n",
    "            raw_df = df\n",
    "        else:\n",
    "            raw_df = raw_df.append(df, ignore_index=True)\n",
    "            \n",
    "        print('File: {}, DataSet Length: {}'.format(os.path.join(dataset_dir, filename), len(df)))\n",
    "        count += 1\n",
    "    else:\n",
    "        continue\n",
    "print('Total Length: {}'.format(len(raw_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Read saved list of data from object into a dataframe\n",
    "# raw_df = pd.read_pickle('DataSet/data_07-10-18.pkl')\n",
    "# print(len(raw_df))\n",
    "# raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_width = len(raw_df['data'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out key counts less than threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "key_count = collections.Counter(raw_df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 0.5 # Bar width\n",
    "figsize = (15, 4)\n",
    "\n",
    "def plot_key_hist(most_common):\n",
    "    if len(most_common) > 30:\n",
    "        most_common = most_common[:30]\n",
    "        \n",
    "    hist_labels, hist_values = zip(*most_common) # Show only a subset of all keys\n",
    "    indexes = np.arange(len(hist_labels))\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(indexes, hist_values, width)\n",
    "    plt.xticks(indexes + width * 0.5, hist_labels, rotation='vertical')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEnCAYAAAAKIrrIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuUZWV95vHvY7cBjCIwtC1p0EaDFyCi0Fwy0YmKBiZt\nxCSKGCNkQmAZ0JCbpkmMjo6MaIxrhqgYYoztJSGYSCAiSZCYqFGE5hIQlEVHINDDpfEG3rj5mz/2\nW3Asuqmqrn3qVO/+ftaqdfZ+6+z9e0/16ar9nHfvd6eqkCRJkiRt3R4x6Q5IkiRJkubPcCdJkiRJ\nA2C4kyRJkqQBMNxJkiRJ0gAY7iRJkiRpAAx3kiRJkjQAhjtJkiRJGgDDnSRJkiQNgOFOkiRJkgZg\n6aQ7MJNdd921Vq5cOeluSJIkSdJEXHrppXdU1bKZnrfow93KlStZt27dpLshSZIkSROR5MbZPM/T\nMiVJkiRpAAx3kiRJkjQAhjtJkiRJGgDDnSRJkiQNgOFOkiRJkgZgVuEuyQ1JrkpyRZJ1rW2XJBck\nua497jzy/JOTrE9ybZLDRtoPaPtZn+S0JOn/JUmSJEnStmcuI3fPq6pnVtWqtr4GuLCq9gIubOsk\n2Rs4CtgHOBx4b5IlbZvTgeOAvdrX4fN/CZIkSZKk+ZyWeQSwti2vBV4y0n5mVd1dVdcD64GDkuwG\n7FhVF1VVAR8a2UaSJEmSNA+zDXcFfCrJpUmOb23Lq+qWtnwrsLwtrwBuGtn25ta2oi1Pb3+IJMcn\nWZdk3caNG2fZRUmSJEnadi2d5fOeXVUbkjwOuCDJV0a/WVWVpPrqVFWdAZwBsGrVqt7226eVa86b\n8zY3nLp6DD2RJEmSpFmO3FXVhvZ4O3A2cBBwWzvVkvZ4e3v6BmCPkc13b20b2vL0dkmSJEnSPM0Y\n7pL8aJLHTC0DPwN8CTgXOKY97RjgnLZ8LnBUku2S7Ek3ccrF7RTOO5Mc0mbJPHpkG0mSJEnSPMzm\ntMzlwNntrgVLgb+sqn9IcglwVpJjgRuBIwGq6uokZwHXAPcBJ1bV/W1fJwAfBHYAzm9fkiRJkqR5\nmjHcVdVXgf020f414NDNbHMKcMom2tcB+869m5IkSZKkhzOfWyFIkiRJkhYJw50kSZIkDYDhTpIk\nSZIGwHAnSZIkSQNguJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIkSRoAw50kSZIk\nDYDhTpIkSZIGwHAnSZIkSQNguJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIkSRoA\nw50kSZIkDYDhTpIkSZIGwHAnSZIkSQNguJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7\nSZIkSRoAw50kSZIkDYDhTpIkSZIGwHAnSZIkSQNguJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5Ik\nSZI0ALMOd0mWJLk8ySfa+i5JLkhyXXvceeS5JydZn+TaJIeNtB+Q5Kr2vdOSpN+XI0mSJEnbprmM\n3J0EfHlkfQ1wYVXtBVzY1kmyN3AUsA9wOPDeJEvaNqcDxwF7ta/D59V7SZIkSRIwy3CXZHdgNfD+\nkeYjgLVteS3wkpH2M6vq7qq6HlgPHJRkN2DHqrqoqgr40Mg2kiRJkqR5mO3I3f8BXg/8YKRteVXd\n0pZvBZa35RXATSPPu7m1rWjL09slSZIkSfM0Y7hL8iLg9qq6dHPPaSNx1VenkhyfZF2SdRs3buxr\nt5IkSZI0WLMZufsp4MVJbgDOBJ6f5CPAbe1US9rj7e35G4A9RrbfvbVtaMvT2x+iqs6oqlVVtWrZ\nsmVzeDmSJEmStG2aMdxV1clVtXtVraSbKOWfq+qXgXOBY9rTjgHOacvnAkcl2S7JnnQTp1zcTuG8\nM8khbZbMo0e2kSRJkiTNw9J5bHsqcFaSY4EbgSMBqurqJGcB1wD3ASdW1f1tmxOADwI7AOe3L0mS\nJEnSPM0p3FXVvwD/0pa/Bhy6meedApyyifZ1wL5z7aQkSZIk6eHN5T53kiRJkqRFynAnSZIkSQNg\nuJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIkSRoAw50kSZIkDYDhTpIkSZIGwHAn\nSZIkSQNguJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIkSRoAw50kSZIkDYDhTpIk\nSZIGwHAnSZIkSQNguJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIkSRoAw50kSZIk\nDYDhTpIkSZIGwHAnSZIkSQNguJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIkSRoA\nw50kSZIkDYDhTpIkSZIGYMZwl2T7JBcn+fckVyd5c2vfJckFSa5rjzuPbHNykvVJrk1y2Ej7AUmu\nat87LUnG87IkSZIkaduydBbPuRt4flV9O8kjgc8lOR/4BeDCqjo1yRpgDfB7SfYGjgL2AX4M+FSS\np1TV/cDpwHHAF4FPAocD5/f+qgZk5Zrz5vT8G05dPaaeSJIkSVrMZhy5q8632+oj21cBRwBrW/ta\n4CVt+QjgzKq6u6quB9YDByXZDdixqi6qqgI+NLKNJEmSJGkeZnXNXZIlSa4AbgcuqKovAsur6pb2\nlFuB5W15BXDTyOY3t7YVbXl6+6bqHZ9kXZJ1GzdunPWLkSRJkqRt1azCXVXdX1XPBHanG4Xbd9r3\ni240rxdVdUZVraqqVcuWLetrt5IkSZI0WHOaLbOqvgl8mu5audvaqZa0x9vb0zYAe4xstntr29CW\np7dLkiRJkuZpNrNlLkuyU1veAXgh8BXgXOCY9rRjgHPa8rnAUUm2S7InsBdwcTuF884kh7RZMo8e\n2UaSJEmSNA+zmS1zN2BtkiV0YfCsqvpEki8AZyU5FrgROBKgqq5OchZwDXAfcGKbKRPgBOCDwA50\ns2Q6U6YkSZIk9WDGcFdVVwLP2kT714BDN7PNKcApm2hfB+z70C0kSZIkSfMxp2vuJEmSJEmLk+FO\nkiRJkgbAcCdJkiRJA2C4kyRJkqQBMNxJkiRJ0gAY7iRJkiRpAAx3kiRJkjQAhjtJkiRJGgDDnSRJ\nkiQNgOFOkiRJkgbAcCdJkiRJA2C4kyRJkqQBMNxJkiRJ0gAY7iRJkiRpAAx3kiRJkjQAhjtJkiRJ\nGgDDnSRJkiQNgOFOkiRJkgbAcCdJkiRJA7B00h3Q5K1cc96ct7nh1NVj6IkkSZKkLeXInSRJkiQN\ngOFOkiRJkgbAcCdJkiRJA2C4kyRJkqQBMNxJkiRJ0gAY7iRJkiRpAAx3kiRJkjQAhjtJkiRJGgDD\nnSRJkiQNgOFOkiRJkgZg6aQ7oG3HyjXnzXmbG05dPYaeSJIkScPjyJ0kSZIkDcCM4S7JHkk+neSa\nJFcnOam175LkgiTXtcedR7Y5Ocn6JNcmOWyk/YAkV7XvnZYk43lZkiRJkrRtmc3I3X3A71TV3sAh\nwIlJ9gbWABdW1V7AhW2d9r2jgH2Aw4H3JlnS9nU6cBywV/s6vMfXIkmSJEnbrBnDXVXdUlWXteW7\ngC8DK4AjgLXtaWuBl7TlI4Azq+ruqroeWA8clGQ3YMequqiqCvjQyDaSJEmSpHmY0zV3SVYCzwK+\nCCyvqlvat24FlrflFcBNI5vd3NpWtOXp7ZIkSZKkeZp1uEvyaOBvgd+sqjtHv9dG4qqvTiU5Psm6\nJOs2btzY124lSZIkabBmFe6SPJIu2H20qj7emm9rp1rSHm9v7RuAPUY23721bWjL09sfoqrOqKpV\nVbVq2bJls30tkiRJkrTNms1smQH+HPhyVb1r5FvnAse05WOAc0baj0qyXZI96SZOubidwnlnkkPa\nPo8e2UaSJEmSNA+zuYn5TwGvAq5KckVr+33gVOCsJMcCNwJHAlTV1UnOAq6hm2nzxKq6v213AvBB\nYAfg/PYlSZIkSZqnGcNdVX0O2Nz96A7dzDanAKdson0dsO9cOihJkiRJmtmcZsuUJEmSJC1Oszkt\nU9qqrFxz3py3ueHU1WPoiSRJkrRwHLmTJEmSpAEw3EmSJEnSAHhaprSFPP1TkiRJi4nhTlrk5hoi\nDZCSJEnbJsOdJEchJUmSBsBr7iRJkiRpAAx3kiRJkjQAhjtJkiRJGgDDnSRJkiQNgOFOkiRJkgbA\ncCdJkiRJA2C4kyRJkqQBMNxJkiRJ0gAY7iRJkiRpAJZOugOSth0r15w3521uOHX1GHoiSZI0PI7c\nSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIkSRoAw50kSZIkDYDhTpIkSZIGwHAnSZIkSQNguJMk\nSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIkSRoAw50kSZIkDYDhTpIkSZIGwHAnSZIk\nSQOwdNIdkKS+rVxz3py3ueHU1Yu2jiRJ0mzMOHKX5ANJbk/ypZG2XZJckOS69rjzyPdOTrI+ybVJ\nDhtpPyDJVe17pyVJ/y9HkiRJkrZNszkt84PA4dPa1gAXVtVewIVtnSR7A0cB+7Rt3ptkSdvmdOA4\nYK/2NX2fkiRJkqQtNGO4q6rPAF+f1nwEsLYtrwVeMtJ+ZlXdXVXXA+uBg5LsBuxYVRdVVQEfGtlG\nkiRJkjRPWzqhyvKquqUt3wosb8srgJtGnndza1vRlqe3b1KS45OsS7Ju48aNW9hFSZIkSdp2zHu2\nzDYSVz30ZXSfZ1TVqqpatWzZsj53LUmSJEmDtKXh7rZ2qiXt8fbWvgHYY+R5u7e2DW15erskSZIk\nqQdbGu7OBY5py8cA54y0H5VkuyR70k2ccnE7hfPOJIe0WTKPHtlGkiRJkjRPM97nLslfAc8Fdk1y\nM/Am4FTgrCTHAjcCRwJU1dVJzgKuAe4DTqyq+9uuTqCbeXMH4Pz2JUmSJEnqwYzhrqpesZlvHbqZ\n558CnLKJ9nXAvnPqnSRJkiRpVmYMd5KkyVm55rw5b3PDqavH0BNJkrTYGe4kSYZISZIGYN63QpAk\nSZIkTZ7hTpIkSZIGwHAnSZIkSQNguJMkSZKkATDcSZIkSdIAGO4kSZIkaQAMd5IkSZI0AIY7SZIk\nSRoAb2IuSVowC3WzdG/KLknaFhnuJEnaQoZISdJi4mmZkiRJkjQAhjtJkiRJGgBPy5QkaRHz1E9J\n0mw5cidJkiRJA+DInSRJcoRQkgbAkTtJkiRJGgBH7iRJ0oLxXoeSND6O3EmSJEnSADhyJ0mStIUc\nIZS0mDhyJ0mSJEkDYLiTJEmSpAHwtExJkqRFzEloJM2W4U6SJEkLxhApjY+nZUqSJEnSADhyJ0mS\npMFxhFDbIkfuJEmSJGkAHLmTJEmSttBcRwgdHdQ4OXInSZIkSQPgyJ0kSZK0iHn9oGbLcCdJkiTJ\neyoOwIKflpnk8CTXJlmfZM1C15ckSZKkIVrQkbskS4D3AC8EbgYuSXJuVV2zkP2QJEmSNGzb4gjh\nQo/cHQSsr6qvVtU9wJnAEQvcB0mSJEkanIUOdyuAm0bWb25tkiRJkqR5SFUtXLHkpcDhVfVrbf1V\nwMFV9ZppzzseOL6tPhW4dsE6OV67AncMoIZ1FnedIb0W6yzeGtZZ3HWG9Fqss3hrWGfx1rDO4q8z\nV0+sqmUzPWmhZ8vcAOwxsr57a/shVXUGcMZCdWqhJFlXVau29hrWWdx1hvRarLN4a1hncdcZ0mux\nzuKtYZ3FW8M6i7/OuCz0aZmXAHsl2TPJjwBHAecucB8kSZIkaXAWdOSuqu5L8hrgH4ElwAeq6uqF\n7IMkSZIkDdGC38S8qj4JfHKh6y4SC3Gq6UKdzmqdxVtnSK/FOou3hnUWd50hvRbrLN4a1lm8Nayz\n+OuMxYJOqCJJkiRJGo+FvuZOkiRJkjQGhjtJi0o6e8z8TEmSJI0y3A1AOxj+5SRvbOtPSHJQzzXe\nPpu2HuvtnOSgJP9t6mtctcYtyX5JXtO+9pt0f+YjycuSPKYtvyHJx5Ps32eN6s4V31avy5XmLMmH\n2+NJC1Rv+yS/3f7//22S30qyfc81PpLkuCRP63O/m6jz2iQ7j7NGqzP2n1mr89tJVvS9321Jkt2S\nbDeG/R6wibYX9V1nSJLsvYm2506gK1sVr7kboySPAn4HeEJVHZdkL+CpVfWJnuucDvwAeH5VPb39\nofqnqjqwxxqXVdX+09qurKpn9FVjZL+/BpxEdx/EK4BDgC9U1fP7rjVu7WDrOODjrenngTOq6k96\nrrMd8IvASkYmSqqqt/Rc58qqekaSZwNvBf4IeGNVHdxznbXAu6vqkj73u4k6C/JzG6ckv/1w36+q\nd/Vcby1wUlV9s63vDPxxVf1qz3XeuKn2MbynVwF/ADyR7j2Qrkx/v9s282/0LeDSqrqih/1fA7wA\nOB94Lt1reEBVfX2+NabVOwu4C/hIa/olYKeqelmPNZ4HPKd9PRm4HPhMVf3fvmq0Om+luy3TZcAH\ngH+sMRwYLcTPrNV5E3Ak8HXgr4GPVdVtfdYYqfVEYK+q+lSSHYClVXXXOGpNq/v4qrp1jPv/FN17\n7m+r6nd73O9lwNFV9aW2/grgN/v8+5lkCfD2Pvv9MLU+XFWvmqltnjW+BHwYeAewfXtcVVU/2VeN\nIVrw2TK3MX8BXApMvQk3AB8Deg13wMFVtX+SywGq6hvtPoLzluTXgROAJyW5cuRbjwH+rY8am3AS\ncCBwUVU9r31y+7/72nmSz1XVs5PcBYz+EZ86qNuxr1rAsXT/Pt9ptd8OfAHoNdwB59AOFoG7e973\nqPvb42q6kHpeOzjq28HAK5PcCHyHMRxwN2P9uW3iPfbAt+jvvfaY9vhUuv83U/cO/Tng4h72P90z\npoIdPPD75lljqPOdkeXtgRcBXx5DnY8CrwOuovuQbBxWta+/b+svAq4EXp3kY1X1jnnu/33AhcCT\n6N7Lo+GuWnuf9q2q0U/UP90CZm+q6tNJPkP3nn4e8GpgH6DXcFdVb0jyh8DPAP8DeHcLYn9eVf/R\nY6mx/8wAqurNwJuTPAN4OfCvSW6uqhf0WSfJccDxwC50QWh3uvfhoX3W2Yw/p/sbNBZV9YIkAR4y\najRPLwX+Jskv0X1ocTTd+643VXV/+/B1IewzutKC5UNGJ+fpYODtwOfp/tZ9FPipnmuQ5Hq635Ub\n+/6wehIMd+P15Kp6eft0hqr6bvuF0bd723+qAkiyjP4OUv6S7tPgtwFrRtrv6vvT4BHfr6rvJyHJ\ndlX1lSRP7WvnVfXs9viYmZ7bg/BgIKItj+M9sHtVHT6G/U63IcmfAi8E3t5GvsZxevdhY9jnpoz1\n57YQ77F2MEc7EN5/6pPzJP8TOG8MJR+RZOeq+karswtj+FtSVX88up7knXT3SO3bxqo6d+anzcvu\ndP8234YHRlfOA/4bXRibV7irqtOA05KcXlW/Pt/OzsJlSQ6pqosAkhwMrOuzQJILgR+l+zDss8CB\nVXV7nzWmVFUluRW4FbgP2JnuIPyCqnp9T2XG/jOb5na61/M14HFj2P+JwEHAFwGq6rok46jzEFU1\ntmA3UqOAXu/DXFVfTXIU8HfAfwI/U1Xf67NGc3mSc+kGEx74kKyqPr75TWYvycnA7wM7JLlzqhm4\nh/5vIXAv8D1gB7oP+a6vqt4/hKuqPfve5yQZ7sbrnnaqwlToejLjGVU5DTgbeFySU+g+HXpDHzuu\nqm/RjWy8oo/9zdLNSXai+wV4QZJvADcuYP0+/QXwxSRnt/WX0H3q2LfPJ/mJqrpqDPsedSRwOPDO\nqvpmkt3oRj16VVUL9e+9UD+3hbCc7o/rlHtaW9/+GPhCko+19ZcBp4yhznSPogtJfXtTkvfTjXw9\n8Pu5rwOh5nH88O/+e4HlVfW9JL39TVigYAfdp/OfT/Kfbf0JwLVJrqK/EfYrW5196f4GfTPJF/o+\nGG6nzh8N3AG8H3hdVd2b5BHAdcC8wt3UzwR4JA/+zIruNOCvzGffm6l3At3v6WV0B/fHVVXvI4TA\n3VV1z9Tn1UmWsumzFLZ5I++BKbsAS+iODRjDGSnb04X60UtZigcvD5mvz1TV25KcWlVrZn76vFxC\nd4bNgcCuwPuS/GLfpzMPjdfcjVGSF9KFrL2Bf6IbSv6VqvqXMdR6Gt3pEAEurKpxnL604JL8NPBY\n4B+q6p6Znr8YpZtwZOo0ic9W1eVjqHEN8OPA9XQHkeM6jXEQRv7YLgX2Ar7KVv5zS/IHdAd1ox8k\n/HVVvW0MtfbmwQOHfx7HweO0A6IldAerb6mqd/dc5yPA0+g+pZ/6RLj6vIawnfb383QHKdCdMnsu\nXVA+o6pe2VethdCutdqsPj+cSTeB068Avws8vqp6negiyZuBD2yqz0mePt+/pQv5s2r13kb3/37e\n13LOUOcdwDfpgvFr6S7fuKaq/mCcdbdGC/0eGLckl1bVAdnEXAxjqLWqqtZNa3tVVX14nHW3doa7\nMUvyX+gmBAndNWR3TLhLGqDN/fHY2v5oLJSh/bGd0j5IeE5b/cw4PkhYKNP+je4Dbquq+8ZQ59qq\n6u2074eps4oHrxX5t+kHLPphSV5D914+ALiB7tTMz1bVP0+yX+q0kc1j6a4ZC90p0+8fx2Q0mpsk\nTwFOpzs7YN92/eWLq6qX6+OTXEQ3sn4E3aQ9P6SqfqOPOtpyhrsxSvLzdJ9qf6ut7wQ8t6r+brI9\nkyQBJPkL4I/GdOqatlCS36ULdJeOI9RrfpL8KN318fe39SXAdlX13cn2TEn+le5yiT+tqme1ti9V\n1b497X9Xutl53w48ZFbjqlrbRx1tOcPdGCW5oqqeOa3t8qn/bJKkyUryZbrZ/jylWZqlNnrzgpFJ\ngh5Ndwum/zrZninJJVV14Ojx5qaOR3uos19V/Xuf+1Q/nFBlvDY1i6A/c0laPBZilllpaLafCnYA\nVfXtdPf21eTd0Sbwm5rM76XALX3tPMnr2+1bfi3JQ0aIPC1z8gwa47UuybuA97T1E+mmvZYkLQJb\n6/WV0oR9J8n+VXUZQJID6Kas1+SdSHdLgqcl2UB3VkKfkzZNTTLkdcOLlKdljlE7J/0P6c5NBrgA\neGu1G1pLkiRtbZIcCJwJ/D+6U5kfD7y8qvwAe8KS7FlV17dj0EdU1V1TbZPumxaG4U6SJElzkuSR\nwNRMs9dW1b2T7I86m7pFwdTtC3qu8xS6W5SsZORMwKp6/ua20cLwtMwxSrKM7gao+9DdVBLwjS9J\nkrZ6T6W7j+/2wP7thtwfmnCftlntfsf7AI9N8gsj39qRkWPQHn0MeB/wfuD+MexfW8hwN14fpbsH\nyIuAVwPHABsn2iNJkqR5SPIm4Ll04e6TwH8HPgcY7ibnqXTHmzsBPzfSfhdw3Bjq3VdVp49hv5on\nT8sco6lh8CRXTk2rPTVF7aT7JkmStCWSXAXsB1xeVfslWQ58pKpeOOGubfOS/GRVfWGM+9+lLf4G\ncDtwNt1tZACoqq+Pq7Zmx5G78Zo6//yWJKvpLjze5WGeL0mStNh9r6p+kOS+JDvSHeTvMelOCYD1\nSX6fh14L96s97f9SutsspK2/rq1PeVJPdbSFDHfj9dYkjwV+B/gTuvOef2uyXZIkSZqXdUl2Av6M\n7mD/28DYRos0J+cAnwU+xRiuhauqPQGSHAn8Q1XdmeQPgf2B/9V3Pc2dp2VKkiRpiyRZCexYVVdO\nuCsCklxRVc9cgDpXVtUzkjybLtS9E3hjVR087tp6eI+YdAeGLMmTkvx9kjuS3J7knCQOV0uSpK1a\nkl9I8i7gtcCTJ90fPeATSX52AepMjQquBv6sqs4DfmQB6moGjtyNUZKLgPcAf9WajgJe66cakiRp\na5XkvcCP8+DxzcuB/6iqEyfXKwEkuQt4FHAP3dwPAaqqduy5zieADcAL6U7J/B5wcVXt12cdzZ3h\nboxGZ8kcaft33/iSJGlrleQrwNOrHUQmeQRwdVU9fbI9U/u3eCWwZ1W9JckTgN2q6os913kUcDhw\nVVVdl2Q34Ceq6p/6rKO587TM8To/yZokK5M8McnrgU8m2WVkKllJkqStyXrgCSPre7Q2Td57gEOA\nV7T1u4B3912kqr5bVR+vquva+i0Gu8XBkbsxSnL9yOrUD3pq6tiqKq+/kyRJW5Uk/wocCFzcmg4E\n1gHfAqiqF0+oa9u8JJdV1f5JLq+qZ7U2zxrbhngrhPH6PTYxTWxVXTbhfkmSJG2pN066A9qse5Ms\noQ0qJFkG/GCyXdJCMtyN1xuq6qw2Tezz6aaJPR1wQhVJkrS1WseDNzJ/CvA04PyqunfC/RKcBpwN\nPC7JKcBLgTdMtktaSJ6WOUZTQ+JJ3kZ3welfjg6TS5IkbW2SXAo8B9gZ+DfgEuCeqnrlRDsmAJI8\nDTiU7lKgC6vqyxPukhaQ4W6MnCZWkiQNzch1Xa8Fdqiqd3hdl7Q4OFvmeB0J/CNwWFV9E9gFeN1k\nuyRJkjQvSfKTdFPun9faPKaUFgGvuRujqvou8PGR9VuAWybXI0mSpHk7CTgZOLuqrk7yJODTE+6T\nJDwtU5IkSXOQZM+qun5a24FVdcmk+iSp4xC6JEmS5uJvkqyYWkny08AHJtgfSY3hTpIkSXPxauDv\nkjw+yc/STb//sxPukyQ8LVOSJElz1CZU+VPg+8Dqqto44S5JwnAnSZKkWUjy98DogePedBPFfQOg\nql48iX5JepCzZUqSJGk23jnpDkh6eI7cSZIkadaS7AncUlXfb+s7AMur6oaJdkySE6pIkiRpTj4G\n/GBk/f7WJmnCDHeSJEmai6VVdc/USlv+kQn2R1JjuJMkSdJcbEzywOQpSY4A7phgfyQ1XnMnSZKk\nWUvyZOCjwI8BAW4Cjq6q9RPtmCTDnSRJkuYuyaMBqurbk+6LpI7hTpIkSXOSZDWwD7D9VFtVvWVy\nPZIEXnMnSZKkOUjyPuDlwGvpTst8GfDEiXZKEuDInSRJkuYgyZVV9YyRx0cD51fVcybdN2lb58id\nJEmS5uJ77fG7SX4MuBfYbYL9kdQsnXQHJEmStFX5RJKdgHcAl7a290+wP5IaT8uUJEnSrCXZAfh1\n4DlAAZ+IuenaAAAAsUlEQVQFTq+q70+0Y5IMd5IkSZq9JGcBdwEfaU2/BDy2qo6cXK8kgeFOkiRJ\nc5Dkmqrae6Y2SQvPCVUkSZI0F5clOWRqJcnBwLoJ9kdS44QqkiRJmlGSq+iusXsk8Pkk/9nWnwh8\nZZJ9k9TxtExJkiTNKMnD3qi8qm5cqL5I2jTDnSRJkiQNgNfcSZIkSdIAGO4kSZIkaQAMd5IkSZI0\nAIY7SZIkSRoAw50kSZIkDcD/B7kF+cRN5MNvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d57c0fcb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_key_hist(key_count.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Counter.most_common of Counter({'space': 4990, 'e': 3070, 't': 2414, 'a': 2135, 'i': 1858, 'o': 1774, 'n': 1766, 's': 1738, 'r': 1490, 'h': 1109, 'l': 1102, 'd': 877, 'c': 837, 'u': 629, 'm': 623, 'g': 591, 'f': 517, 'p': 479, 'w': 431, 'y': 429, 'b': 392, 'v': 311, 'backspace': 309, '.': 283, ',': 246, 'k': 188, 'enter': 148, 'shift': 120, 'x': 107, \"'\": 76, '0': 69, 'z': 67, 'ctrl_l': 60, '-': 54, '1': 45, '2': 43, 'q': 42, 'delete': 38, 'down': 38, '9': 35, 'j': 26, '3': 24, '5': 20, 'esc': 17, '/': 17, 'left': 16, ';': 16, '7': 15, '8': 14, '6': 14, '4': 14, 'up': 10, 'right': 8, 'tab': 4, '=': 4, '`': 1})>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_count.most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Data Size: 13904, Class Count: 8, Threshold: 1737\n"
     ]
    }
   ],
   "source": [
    "# Maximize DataSet Size By Finding Optimal Threshold\n",
    "max_data_size = 0\n",
    "max_class_cnt = 0\n",
    "threshold_max = 0\n",
    "for _, v in key_count.most_common():\n",
    "    threshold = v - 1\n",
    "    min_thresh_cnts = [count for key, count in zip(key_count.keys(), key_count.values()) if count > threshold]\n",
    "    class_cnt = len(min_thresh_cnts)\n",
    "    data_size = min(min_thresh_cnts)*len(min_thresh_cnts)\n",
    "    if data_size > max_data_size:\n",
    "        max_data_size = data_size\n",
    "        max_class_cnt = class_cnt\n",
    "        threshold_max = threshold\n",
    "print('Max Data Size: {}, Class Count: {}, Threshold: {}'.format(max_data_size, max_class_cnt, threshold_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get list of keys with counts greater than threshold\n",
    "threshold = threshold_max\n",
    "min_thresh_keys = [key for key, count in zip(key_count.keys(), key_count.values()) if count > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_thresh_df = raw_df[raw_df['key'].isin(min_thresh_keys)] # Filter dataframe to only include keys > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_max_thresh(grouped_class):\n",
    "    return grouped_class.sample(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep same number of samples in each class by throwing away everything past the threshold\n",
    "df = min_thresh_df.groupby(['key']).apply(trim_max_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot truncated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truncated_count = collections.Counter(df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEPCAYAAADh3T2TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d576b650b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_key_hist(truncated_count.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip to Load If Normalized Data Already Exists on Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = df['data'].values\n",
    "input_data = np.stack(input_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stephen\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int16 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "normalized_data = scaler.fit_transform(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = len(set(df['key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_str = [str(key) for key in df['key']]\n",
    "lb = preprocessing.LabelBinarizer() # Create encoder\n",
    "lb.fit(list(set(labels_str)))\n",
    "labels = lb.transform(labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'e', 'i', 'n', 'o', 's', 'space', 't'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Training and Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape to add 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13896, 10240, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data = normalized_data.reshape((normalized_data.shape[0], normalized_data.shape[1], 1))\n",
    "# labels = labels.reshape((labels.shape[0], labels.shape[1], 1))\n",
    "normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    normalized_data, \n",
    "    labels, \n",
    "    test_size=0.1, \n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs(data_width, n_classes):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    :param data_width: The total number of samples in the recorded data point\n",
    "    :param n_classes: Number of Classes\n",
    "    :return: Tuple of (tensor of input audio data, key press labels, learning rate, keep_prob)\n",
    "    \"\"\"\n",
    "    # TODO: Add audio channels to input\n",
    "    \n",
    "    with tf.name_scope(\"Inputs\"):\n",
    "        audio_inputs = tf.placeholder(tf.float32, [None, data_width, 1], name='inputs')\n",
    "    with tf.name_scope(\"Targets\"):\n",
    "        key_labels = tf.placeholder(tf.float32, [None, n_classes], name='labels')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_probability')\n",
    "\n",
    "    return audio_inputs, key_labels, learning_rate, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(X, keep_prob, n_classes):\n",
    "    \"\"\"\n",
    "    Create the network\n",
    "    :param X: Tensor of input recording(s)\n",
    "    :param keep_prob: Tensor for the keep probability\n",
    "    :param n_classes: Number of Classes\n",
    "    :return: Tuple of (tensor output of the classifier, tensor logits of the classifier)\n",
    "    \"\"\"    \n",
    "    # Hyperparameters\n",
    "    alpha = 0.2\n",
    "    h_dim = 32\n",
    "    \n",
    "    #print(\"X: {}\".format(X.shape))\n",
    "     \n",
    "    with tf.name_scope(\"Hidden_Layer1\"):\n",
    "        #h1 = tf.layers.dense(X, h_dim, activation=None)\n",
    "        h1 = tf.layers.conv1d(X, h_dim, 100, 10, 'same', activation=None)\n",
    "        h1 = tf.layers.max_pooling1d(h1, 5, 2, 'same')\n",
    "        h1 = tf.nn.dropout(h1, keep_prob) # Regularization\n",
    "        h1 = tf.maximum(h1*alpha, h1) # Leaky ReLu\n",
    "        h1 = tf.layers.batch_normalization(h1)\n",
    "        \n",
    "    #print(\"h1: {}\".format(h1.shape))\n",
    "\n",
    "    with tf.name_scope(\"Hidden_Layer2\"):\n",
    "        #h2 = tf.layers.dense(h1, h_dim, activation=None)\n",
    "        h2 = tf.layers.conv1d(h1, h_dim*2, 50, 5, 'same', activation=None)\n",
    "        #h2 = tf.layers.maxpool2d(h2, 5, 2, 'same')\n",
    "        h2 = tf.nn.dropout(h2, keep_prob) # Regularization        \n",
    "        h2 = tf.maximum(h2*alpha, h2) # Leaky ReLu\n",
    "        h2 = tf.layers.batch_normalization(h2)\n",
    "        \n",
    "    #print(\"h2: {}\".format(h2.shape))\n",
    "\n",
    "    with tf.name_scope(\"Hidden_Layer3\"):\n",
    "        #h3 = tf.layers.dense(h2, h_dim, activation=None)\n",
    "        h3 = tf.layers.conv1d(h2, h_dim*3, 25, 2, 'same', activation=None)\n",
    "        #h3 = tf.layers.maxpool2d(h3, 3, 2, 'same')\n",
    "        h3 = tf.nn.dropout(h3, keep_prob) # Regularization\n",
    "        h3 = tf.maximum(h3*alpha, h3) # Leaky ReLu\n",
    "        h3 = tf.layers.batch_normalization(h3)\n",
    "        \n",
    "    with tf.name_scope(\"Hidden_Layer4\"):\n",
    "        h4 = tf.layers.conv1d(h3, h_dim*4, 10, 1, 'same', activation=None)\n",
    "        h4 = tf.nn.dropout(h4, keep_prob) # Regularization\n",
    "        h4 = tf.maximum(h4*alpha, h4) # Leaky ReLu\n",
    "        h4 = tf.layers.batch_normalization(h4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.name_scope(\"Output\"):\n",
    "        flat_dim = int(h4.get_shape()[1])*int(h4.get_shape()[2])\n",
    "        flat = tf.reshape(h4, [-1, flat_dim])\n",
    "        #print(\"flat: {}\".format(flat.shape))\n",
    "        logits = tf.layers.dense(flat, n_classes, activation=None, name='logits')\n",
    "        #print(\"logits: {}\".format(logits.shape))\n",
    "        #out = tf.nn.softmax(logits, name='softmax_out')\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Validation_Stats\"):\n",
    "        validation_loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "        validation_accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "        train_accuracy = session.run(accuracy, feed_dict={x: train_features[:1000], y: train_labels[:1000], keep_prob: 1.0})\n",
    "        print(\"Train Accuracy: {}, Validation Accuracy: {}, Validation Loss: {}\".format(train_accuracy, validation_accuracy, validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x, y, learn_rate, keep_prob = model_inputs(data_width, n_classes)\n",
    "\n",
    "#Model\n",
    "logits = network(x, keep_prob, n_classes)\n",
    "\n",
    "with tf.name_scope(\"Cost\"):\n",
    "    # Cost and Optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y, name='loss'), name='cost')\n",
    "    \n",
    "with tf.name_scope(\"Train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate, name='optimizer').minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1), name='prediction')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the graph for TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_writer = tf.summary.FileWriter('./logs/2', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 16\n",
    "keep_probability = 0.70\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy to beat (Min of 3 classes)\n",
    "print(\"{:.3}%\".format((1/n_classes)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0: Train Accuracy: 0.13199999928474426, Validation Accuracy: 0.1258992850780487, Validation Loss: 2.073786973953247\n",
      "Epoch 1: Train Accuracy: 0.27400001883506775, Validation Accuracy: 0.2755395770072937, Validation Loss: 1.568467617034912\n",
      "Epoch 2: Train Accuracy: 0.30800002813339233, Validation Accuracy: 0.3050360083580017, Validation Loss: 1.4813799858093262\n",
      "Epoch 3: Train Accuracy: 0.4399999976158142, Validation Accuracy: 0.4374100863933563, Validation Loss: 0.9968374967575073\n",
      "Epoch 4: Train Accuracy: 0.4710000157356262, Validation Accuracy: 0.4705035984516144, Validation Loss: 0.7620723247528076\n",
      "Epoch 5: Train Accuracy: 0.5049999356269836, Validation Accuracy: 0.5151079297065735, Validation Loss: 0.7107069492340088\n",
      "Epoch 6: Train Accuracy: 0.5379999876022339, Validation Accuracy: 0.5244604349136353, Validation Loss: 0.6349624395370483\n",
      "Epoch 7: Train Accuracy: 0.5359999537467957, Validation Accuracy: 0.533812940120697, Validation Loss: 0.5715106129646301\n",
      "Epoch 8: Train Accuracy: 0.5719999670982361, Validation Accuracy: 0.5546762943267822, Validation Loss: 0.5418459177017212\n",
      "Epoch 9: Train Accuracy: 0.5830000042915344, Validation Accuracy: 0.5654675960540771, Validation Loss: 0.484868586063385\n",
      "Epoch 10: Train Accuracy: 0.5879999995231628, Validation Accuracy: 0.5741007328033447, Validation Loss: 0.509524405002594\n",
      "Epoch 11: Train Accuracy: 0.6039999723434448, Validation Accuracy: 0.5805755257606506, Validation Loss: 0.4989507794380188\n",
      "Epoch 12: Train Accuracy: 0.6249999403953552, Validation Accuracy: 0.5920863151550293, Validation Loss: 0.4396919012069702\n",
      "Epoch 13: Train Accuracy: 0.6269999742507935, Validation Accuracy: 0.5942445993423462, Validation Loss: 0.4557180404663086\n",
      "Epoch 14: Train Accuracy: 0.6480000019073486, Validation Accuracy: 0.6014388203620911, Validation Loss: 0.37739795446395874\n",
      "Epoch 15: Train Accuracy: 0.6389999389648438, Validation Accuracy: 0.6086331605911255, Validation Loss: 0.36083629727363586\n",
      "Epoch 16: Train Accuracy: 0.6579999327659607, Validation Accuracy: 0.6187050342559814, Validation Loss: 0.3204546272754669\n",
      "Epoch 17: Train Accuracy: 0.6629999876022339, Validation Accuracy: 0.6230216026306152, Validation Loss: 0.35074788331985474\n",
      "Epoch 18: Train Accuracy: 0.6759999394416809, Validation Accuracy: 0.6352517604827881, Validation Loss: 0.3386096954345703\n",
      "Epoch 19: Train Accuracy: 0.6839999556541443, Validation Accuracy: 0.6410071849822998, Validation Loss: 0.29353266954421997\n",
      "Epoch 20: Train Accuracy: 0.6930000185966492, Validation Accuracy: 0.633093535900116, Validation Loss: 0.26227396726608276\n",
      "Epoch 21: Train Accuracy: 0.7120000720024109, Validation Accuracy: 0.6625900268554688, Validation Loss: 0.24727289378643036\n",
      "Epoch 22: Train Accuracy: 0.7130000591278076, Validation Accuracy: 0.661151111125946, Validation Loss: 0.2463855892419815\n",
      "Epoch 23: Train Accuracy: 0.7269999980926514, Validation Accuracy: 0.6733813285827637, Validation Loss: 0.24913665652275085\n",
      "Epoch 24: Train Accuracy: 0.7350000143051147, Validation Accuracy: 0.6863309144973755, Validation Loss: 0.23336157202720642\n",
      "Epoch 25: Train Accuracy: 0.7300000190734863, Validation Accuracy: 0.6928057670593262, Validation Loss: 0.18449988961219788\n",
      "Epoch 26: Train Accuracy: 0.7450000047683716, Validation Accuracy: 0.6942445635795593, Validation Loss: 0.16866770386695862\n",
      "Epoch 27: Train Accuracy: 0.7499999403953552, Validation Accuracy: 0.6964027881622314, Validation Loss: 0.15446817874908447\n",
      "Epoch 28: Train Accuracy: 0.7540000081062317, Validation Accuracy: 0.6956834197044373, Validation Loss: 0.1760762631893158\n",
      "Epoch 29: Train Accuracy: 0.7749999761581421, Validation Accuracy: 0.7093525528907776, Validation Loss: 0.15390446782112122\n",
      "Epoch 30: Train Accuracy: 0.7790000438690186, Validation Accuracy: 0.7194244861602783, Validation Loss: 0.15968090295791626\n",
      "Epoch 31: Train Accuracy: 0.781000018119812, Validation Accuracy: 0.7100719213485718, Validation Loss: 0.15920314192771912\n",
      "Epoch 32: Train Accuracy: 0.7820000052452087, Validation Accuracy: 0.7179856300354004, Validation Loss: 0.12353788316249847\n",
      "Epoch 33: Train Accuracy: 0.7890000343322754, Validation Accuracy: 0.7143884897232056, Validation Loss: 0.1703740954399109\n",
      "Epoch 34: Train Accuracy: 0.800000011920929, Validation Accuracy: 0.7287770509719849, Validation Loss: 0.1173279881477356\n",
      "Epoch 35: Train Accuracy: 0.796000063419342, Validation Accuracy: 0.7187050580978394, Validation Loss: 0.1344691663980484\n",
      "Epoch 36: Train Accuracy: 0.7960000038146973, Validation Accuracy: 0.7237410545349121, Validation Loss: 0.13874630630016327\n",
      "Epoch 37: Train Accuracy: 0.8050000667572021, Validation Accuracy: 0.7215827703475952, Validation Loss: 0.13353773951530457\n",
      "Epoch 38: Train Accuracy: 0.7960000038146973, Validation Accuracy: 0.7151079177856445, Validation Loss: 0.1346178948879242\n",
      "Epoch 39: Train Accuracy: 0.8230000138282776, Validation Accuracy: 0.7352519035339355, Validation Loss: 0.14199241995811462\n",
      "Epoch 40: Train Accuracy: 0.8050000071525574, Validation Accuracy: 0.7287769913673401, Validation Loss: 0.16831915080547333\n",
      "Epoch 41: Train Accuracy: 0.8149999380111694, Validation Accuracy: 0.735251784324646, Validation Loss: 0.09875363111495972\n",
      "Epoch 42: Train Accuracy: 0.8240000605583191, Validation Accuracy: 0.7381294369697571, Validation Loss: 0.10673059523105621\n",
      "Epoch 43: Train Accuracy: 0.8309999704360962, Validation Accuracy: 0.7381294965744019, Validation Loss: 0.08108708262443542\n",
      "Epoch 44: Train Accuracy: 0.8199999332427979, Validation Accuracy: 0.7395683526992798, Validation Loss: 0.15948724746704102\n",
      "Epoch 45: Train Accuracy: 0.8300000429153442, Validation Accuracy: 0.7561150789260864, Validation Loss: 0.12233682721853256\n",
      "Epoch 46: Train Accuracy: 0.8289999961853027, Validation Accuracy: 0.7424460053443909, Validation Loss: 0.1024148017168045\n",
      "Epoch 47: Train Accuracy: 0.8270000219345093, Validation Accuracy: 0.7395683526992798, Validation Loss: 0.07124576717615128\n",
      "Epoch 48: Train Accuracy: 0.8289999961853027, Validation Accuracy: 0.7460431456565857, Validation Loss: 0.08838700503110886\n",
      "Epoch 49: Train Accuracy: 0.8450000286102295, Validation Accuracy: 0.7517985105514526, Validation Loss: 0.07739539444446564\n",
      "Epoch 50: Train Accuracy: 0.8500000238418579, Validation Accuracy: 0.7575539350509644, Validation Loss: 0.13477444648742676\n",
      "Epoch 51: Train Accuracy: 0.8500000834465027, Validation Accuracy: 0.7525179386138916, Validation Loss: 0.09642846882343292\n",
      "Epoch 52: Train Accuracy: 0.8529999852180481, Validation Accuracy: 0.743884801864624, Validation Loss: 0.06501012295484543\n",
      "Epoch 53: Train Accuracy: 0.8469999432563782, Validation Accuracy: 0.7618705034255981, Validation Loss: 0.08023902773857117\n",
      "Epoch 54: Train Accuracy: 0.8580000400543213, Validation Accuracy: 0.7510790824890137, Validation Loss: 0.05753706768155098\n",
      "Epoch 55: Train Accuracy: 0.8520000576972961, Validation Accuracy: 0.7532373666763306, Validation Loss: 0.10416637361049652\n",
      "Epoch 56: Train Accuracy: 0.8640000224113464, Validation Accuracy: 0.7604316473007202, Validation Loss: 0.08900892734527588\n",
      "Epoch 57: Train Accuracy: 0.8650000095367432, Validation Accuracy: 0.7589927911758423, Validation Loss: 0.06045522540807724\n",
      "Epoch 58: Train Accuracy: 0.8750001192092896, Validation Accuracy: 0.7625899314880371, Validation Loss: 0.0662192553281784\n",
      "Epoch 59: Train Accuracy: 0.8859999775886536, Validation Accuracy: 0.7633092999458313, Validation Loss: 0.03846655413508415\n",
      "Epoch 60: Train Accuracy: 0.8730000257492065, Validation Accuracy: 0.7517985105514526, Validation Loss: 0.041756533086299896\n",
      "Epoch 61: Train Accuracy: 0.8830000162124634, Validation Accuracy: 0.7618705034255981, Validation Loss: 0.0504852719604969\n",
      "Epoch 62: Train Accuracy: 0.8709999918937683, Validation Accuracy: 0.7503597140312195, Validation Loss: 0.037276480346918106\n",
      "Epoch 63: Train Accuracy: 0.8769999742507935, Validation Accuracy: 0.7618704438209534, Validation Loss: 0.037041060626506805\n",
      "Epoch 64: Train Accuracy: 0.8920000791549683, Validation Accuracy: 0.7633093595504761, Validation Loss: 0.06366610527038574\n",
      "Epoch 65: Train Accuracy: 0.8999999761581421, Validation Accuracy: 0.765467643737793, Validation Loss: 0.04135884717106819\n",
      "Epoch 66: Train Accuracy: 0.8820000290870667, Validation Accuracy: 0.7546762228012085, Validation Loss: 0.048953909426927567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Train Accuracy: 0.8820000290870667, Validation Accuracy: 0.7669064998626709, Validation Loss: 0.048953283578157425\n",
      "Epoch 68: Train Accuracy: 0.9049999713897705, Validation Accuracy: 0.7755395174026489, Validation Loss: 0.0366734080016613\n",
      "Epoch 69: Train Accuracy: 0.893000066280365, Validation Accuracy: 0.7597122192382812, Validation Loss: 0.0528397299349308\n",
      "Epoch 70: Train Accuracy: 0.9070000648498535, Validation Accuracy: 0.7769784331321716, Validation Loss: 0.044560112059116364\n",
      "Epoch 71: Train Accuracy: 0.8970000743865967, Validation Accuracy: 0.7669064998626709, Validation Loss: 0.0359061174094677\n",
      "Epoch 72: Train Accuracy: 0.8959999680519104, Validation Accuracy: 0.764748215675354, Validation Loss: 0.016153384000062943\n",
      "Epoch 73: Train Accuracy: 0.8959999680519104, Validation Accuracy: 0.770503580570221, Validation Loss: 0.021857034415006638\n",
      "Epoch 74: Train Accuracy: 0.9040000438690186, Validation Accuracy: 0.7726618051528931, Validation Loss: 0.04115051031112671\n",
      "Epoch 75: Train Accuracy: 0.8930000066757202, Validation Accuracy: 0.768345296382904, Validation Loss: 0.0641196221113205\n",
      "Epoch 76: Train Accuracy: 0.9010000228881836, Validation Accuracy: 0.7733812928199768, Validation Loss: 0.07173284888267517\n",
      "Epoch 77: Train Accuracy: 0.9030000567436218, Validation Accuracy: 0.7748201489448547, Validation Loss: 0.031237013638019562\n",
      "Epoch 78: Train Accuracy: 0.9070000052452087, Validation Accuracy: 0.7741007208824158, Validation Loss: 0.01811045967042446\n",
      "Epoch 79: Train Accuracy: 0.9180000424385071, Validation Accuracy: 0.7820143699645996, Validation Loss: 0.030520770698785782\n",
      "Epoch 80: Train Accuracy: 0.9010000228881836, Validation Accuracy: 0.7712229490280151, Validation Loss: 0.05456521362066269\n",
      "Epoch 81: Train Accuracy: 0.8970000147819519, Validation Accuracy: 0.768345296382904, Validation Loss: 0.027741845697164536\n",
      "Epoch 82: Train Accuracy: 0.9270000457763672, Validation Accuracy: 0.7870503067970276, Validation Loss: 0.010328573174774647\n",
      "Epoch 83: Train Accuracy: 0.9169999957084656, Validation Accuracy: 0.7827338576316833, Validation Loss: 0.011980672366917133\n",
      "Epoch 84: Train Accuracy: 0.9270000457763672, Validation Accuracy: 0.7877697944641113, Validation Loss: 0.01282936055213213\n",
      "Epoch 85: Train Accuracy: 0.9300000667572021, Validation Accuracy: 0.7791366577148438, Validation Loss: 0.0184551440179348\n",
      "Epoch 86: Train Accuracy: 0.9290000796318054, Validation Accuracy: 0.7834532260894775, Validation Loss: 0.022781802341341972\n",
      "Epoch 87: Train Accuracy: 0.9260000586509705, Validation Accuracy: 0.7884891629219055, Validation Loss: 0.025345077738165855\n",
      "Epoch 88: Train Accuracy: 0.9259999990463257, Validation Accuracy: 0.773381233215332, Validation Loss: 0.012215583585202694\n",
      "Epoch 89: Train Accuracy: 0.921000063419342, Validation Accuracy: 0.7812950015068054, Validation Loss: 0.020196782425045967\n",
      "Epoch 90: Train Accuracy: 0.9210000038146973, Validation Accuracy: 0.7776978015899658, Validation Loss: 0.012212524190545082\n",
      "Epoch 91: Train Accuracy: 0.9390000700950623, Validation Accuracy: 0.7863309383392334, Validation Loss: 0.02612384781241417\n",
      "Epoch 92: Train Accuracy: 0.9340000152587891, Validation Accuracy: 0.7805755138397217, Validation Loss: 0.018570508807897568\n",
      "Epoch 93: Train Accuracy: 0.9290000200271606, Validation Accuracy: 0.7755395770072937, Validation Loss: 0.020324818789958954\n",
      "Epoch 94: Train Accuracy: 0.9380000233650208, Validation Accuracy: 0.7834532260894775, Validation Loss: 0.04471985995769501\n",
      "Epoch 95: Train Accuracy: 0.9320000410079956, Validation Accuracy: 0.7784172296524048, Validation Loss: 0.024039341136813164\n",
      "Epoch 96: Train Accuracy: 0.9309999942779541, Validation Accuracy: 0.7884891629219055, Validation Loss: 0.02476869523525238\n",
      "Epoch 97: Train Accuracy: 0.9380000829696655, Validation Accuracy: 0.7920863032341003, Validation Loss: 0.039821039885282516\n",
      "Epoch 98: Train Accuracy: 0.924000084400177, Validation Accuracy: 0.7877697944641113, Validation Loss: 0.053019244223833084\n",
      "Epoch 99: Train Accuracy: 0.9420000314712524, Validation Accuracy: 0.7848920822143555, Validation Loss: 0.00705471308901906\n",
      "Epoch 100: Train Accuracy: 0.9199999570846558, Validation Accuracy: 0.7798560857772827, Validation Loss: 0.005869431421160698\n",
      "Epoch 101: Train Accuracy: 0.9399999976158142, Validation Accuracy: 0.7805755138397217, Validation Loss: 0.00964600220322609\n",
      "Epoch 102: Train Accuracy: 0.952000081539154, Validation Accuracy: 0.794964075088501, Validation Loss: 0.01760898157954216\n",
      "Epoch 103: Train Accuracy: 0.9510000348091125, Validation Accuracy: 0.7870503664016724, Validation Loss: 0.022504787892103195\n",
      "Epoch 104: Train Accuracy: 0.9450000524520874, Validation Accuracy: 0.7870503664016724, Validation Loss: 0.018502861261367798\n",
      "Epoch 105: Train Accuracy: 0.9590000510215759, Validation Accuracy: 0.7856115102767944, Validation Loss: 0.005791518371552229\n",
      "Epoch 106: Train Accuracy: 0.9559999704360962, Validation Accuracy: 0.7820143699645996, Validation Loss: 0.006661722436547279\n",
      "Epoch 107: Train Accuracy: 0.9440000653266907, Validation Accuracy: 0.7870503664016724, Validation Loss: 0.008434217423200607\n",
      "Epoch 108: Train Accuracy: 0.9309999942779541, Validation Accuracy: 0.7769783735275269, Validation Loss: 0.0307460930198431\n",
      "Epoch 109: Train Accuracy: 0.9549999833106995, Validation Accuracy: 0.7884892225265503, Validation Loss: 0.006640562787652016\n",
      "Epoch 110: Train Accuracy: 0.9610000848770142, Validation Accuracy: 0.7906475067138672, Validation Loss: 0.0066887084394693375\n",
      "Epoch 111: Train Accuracy: 0.9540001153945923, Validation Accuracy: 0.7877697944641113, Validation Loss: 0.007635687477886677\n",
      "Epoch 112: Train Accuracy: 0.9480000138282776, Validation Accuracy: 0.7834532856941223, Validation Loss: 0.004160042852163315\n",
      "Epoch 113: Train Accuracy: 0.9630001187324524, Validation Accuracy: 0.7949639558792114, Validation Loss: 0.008603011257946491\n",
      "Epoch 114: Train Accuracy: 0.9540001153945923, Validation Accuracy: 0.7870503664016724, Validation Loss: 0.015315581113100052\n",
      "Epoch 115: Train Accuracy: 0.9490001201629639, Validation Accuracy: 0.7870503664016724, Validation Loss: 0.009304186329245567\n",
      "Epoch 116: Train Accuracy: 0.9630001187324524, Validation Accuracy: 0.7978417873382568, Validation Loss: 0.006755777634680271\n",
      "Epoch 117: Train Accuracy: 0.9480000734329224, Validation Accuracy: 0.7884891629219055, Validation Loss: 0.010800512507557869\n",
      "Epoch 118: Train Accuracy: 0.9760000109672546, Validation Accuracy: 0.7949639558792114, Validation Loss: 0.010797609575092793\n",
      "Epoch 119: Train Accuracy: 0.9739999771118164, Validation Accuracy: 0.7913669347763062, Validation Loss: 0.005673224106431007\n",
      "Epoch 120: Train Accuracy: 0.9720000624656677, Validation Accuracy: 0.7999999523162842, Validation Loss: 0.007296424824744463\n",
      "Epoch 121: Train Accuracy: 0.9479999542236328, Validation Accuracy: 0.7827337980270386, Validation Loss: 0.0031351265497505665\n",
      "Epoch 122: Train Accuracy: 0.9720000624656677, Validation Accuracy: 0.7964029312133789, Validation Loss: 0.0025625224225223064\n",
      "Epoch 123: Train Accuracy: 0.9630000591278076, Validation Accuracy: 0.7769784331321716, Validation Loss: 0.00851487461477518\n",
      "Epoch 124: Train Accuracy: 0.9640001058578491, Validation Accuracy: 0.7971222400665283, Validation Loss: 0.005631741136312485\n",
      "Epoch 125: Train Accuracy: 0.9720000624656677, Validation Accuracy: 0.7870503664016724, Validation Loss: 0.038334839046001434\n",
      "Epoch 126: Train Accuracy: 0.9690000414848328, Validation Accuracy: 0.7884891629219055, Validation Loss: 0.0023166309110820293\n",
      "Epoch 127: Train Accuracy: 0.9740000367164612, Validation Accuracy: 0.7892086505889893, Validation Loss: 0.001338415197096765\n",
      "Epoch 128: Train Accuracy: 0.968000054359436, Validation Accuracy: 0.7949640154838562, Validation Loss: 0.0031242589466273785\n",
      "Epoch 129: Train Accuracy: 0.9779999852180481, Validation Accuracy: 0.7856115102767944, Validation Loss: 0.0030672946013510227\n",
      "Epoch 130: Train Accuracy: 0.9650000333786011, Validation Accuracy: 0.7956833839416504, Validation Loss: 0.009515475481748581\n",
      "Epoch 131: Train Accuracy: 0.9650000929832458, Validation Accuracy: 0.7892086505889893, Validation Loss: 0.004488032311201096\n",
      "Epoch 132: Train Accuracy: 0.9620000123977661, Validation Accuracy: 0.793525218963623, Validation Loss: 0.0027478125412017107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: Train Accuracy: 0.9620000720024109, Validation Accuracy: 0.7913669347763062, Validation Loss: 0.003483843756839633\n",
      "Epoch 134: Train Accuracy: 0.9670000076293945, Validation Accuracy: 0.7964028716087341, Validation Loss: 0.001979847438633442\n",
      "Epoch 135: Train Accuracy: 0.9660000205039978, Validation Accuracy: 0.7906475067138672, Validation Loss: 0.0011053240159526467\n",
      "Epoch 136: Train Accuracy: 0.9800000786781311, Validation Accuracy: 0.798561155796051, Validation Loss: 0.0023178430274128914\n",
      "Epoch 137: Train Accuracy: 0.9709999561309814, Validation Accuracy: 0.7956833839416504, Validation Loss: 0.0024570815730839968\n",
      "Epoch 138: Train Accuracy: 0.9790000319480896, Validation Accuracy: 0.7964028716087341, Validation Loss: 0.002053885255008936\n",
      "Epoch 139: Train Accuracy: 0.9800000190734863, Validation Accuracy: 0.7978417277336121, Validation Loss: 0.00297602079808712\n",
      "Epoch 140: Train Accuracy: 0.9790000319480896, Validation Accuracy: 0.798561155796051, Validation Loss: 0.0024371116887778044\n",
      "Epoch 141: Train Accuracy: 0.9780000448226929, Validation Accuracy: 0.7978417277336121, Validation Loss: 0.001574622350744903\n",
      "Epoch 142: Train Accuracy: 0.9829999208450317, Validation Accuracy: 0.7978417873382568, Validation Loss: 0.0015996546717360616\n",
      "Epoch 143: Train Accuracy: 0.9740000367164612, Validation Accuracy: 0.7935251593589783, Validation Loss: 0.001852388959378004\n",
      "Epoch 144: Train Accuracy: 0.9740000367164612, Validation Accuracy: 0.7899280190467834, Validation Loss: 0.005056312307715416\n",
      "Epoch 145: Train Accuracy: 0.9739999771118164, Validation Accuracy: 0.7942445874214172, Validation Loss: 0.0035098539665341377\n",
      "Epoch 146: Train Accuracy: 0.9470000863075256, Validation Accuracy: 0.774100661277771, Validation Loss: 0.005533641669899225\n",
      "Epoch 147: Train Accuracy: 0.9850000143051147, Validation Accuracy: 0.7935251593589783, Validation Loss: 0.004908729810267687\n",
      "Epoch 148: Train Accuracy: 0.9760000705718994, Validation Accuracy: 0.7942445874214172, Validation Loss: 0.005079076625406742\n",
      "Epoch 149: Train Accuracy: 0.9760000109672546, Validation Accuracy: 0.7999999523162842, Validation Loss: 0.0017182512674480677\n",
      "Epoch 150: Train Accuracy: 0.9769999980926514, Validation Accuracy: 0.7964028716087341, Validation Loss: 0.0027490488719195127\n",
      "Epoch 151: Train Accuracy: 0.9880000352859497, Validation Accuracy: 0.7863308787345886, Validation Loss: 0.002587856724858284\n",
      "Epoch 152: Train Accuracy: 0.9819999933242798, Validation Accuracy: 0.7964028716087341, Validation Loss: 0.001493783318437636\n",
      "Epoch 153: Train Accuracy: 0.9880000352859497, Validation Accuracy: 0.8014388084411621, Validation Loss: 0.003861997276544571\n",
      "Epoch 154: Train Accuracy: 0.984000027179718, Validation Accuracy: 0.7971222996711731, Validation Loss: 0.0026635201647877693\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-1582e972384e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                                            \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                            \u001b[0mlearn_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                            keep_prob: keep_probability})\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {}: '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_model_path = './key_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in get_batches(train_features, train_labels, batch_size):\n",
    "            sess.run(optimizer, feed_dict={x: batch_features, \n",
    "                                           y: batch_labels, \n",
    "                                           learn_rate: learning_rate, \n",
    "                                           keep_prob: keep_probability})\n",
    "        if epoch % 1 == 0:\n",
    "            print('Epoch {}: '.format(epoch), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)         \n",
    "            \n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
