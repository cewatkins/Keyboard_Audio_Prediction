{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Version of TensorFlow and Access to GPU\n",
    "This will check to make sure you have the correct version of TensorFlow and access to a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo List\n",
    "- Add several dense layers after convolutional layers\n",
    "- Play with learning rate and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.1.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_dir = 'DataSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: DataSet/2018-07-13_18-39-56_0.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-43-51_0.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-46-04_1.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-47-58_2.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-49-54_3.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-52-16_4.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-54-29_5.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-56-38_6.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-58-30_7.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-00-21_8.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-02-36_9.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-04-42_10.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-06-38_11.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-08-49_12.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-10-48_13.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-12-43_14.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-14-54_15.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-16-54_16.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-19-01_17.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-20-48_18.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-22-54_19.pkl, DataSet Length: 500\n",
      "File: DataSet/data_07-08-18.pkl, DataSet Length: 7150\n",
      "File: DataSet/data_07-10-18_work.pkl, DataSet Length: 8700\n",
      "File: DataSet/data_07-13-18.pkl, DataSet Length: 5400\n",
      "File: DataSet/test_set.pkl, DataSet Length: 500\n",
      "Total Length: 32250\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith(\".pkl\"): \n",
    "        df = pd.read_pickle(os.path.join(dataset_dir, filename))\n",
    "        \n",
    "        if count == 0:\n",
    "            raw_df = df\n",
    "        else:\n",
    "            raw_df = raw_df.append(df, ignore_index=True)\n",
    "            \n",
    "        print('File: {}, DataSet Length: {}'.format(os.path.join(dataset_dir, filename), len(df)))\n",
    "        count += 1\n",
    "    else:\n",
    "        continue\n",
    "print('Total Length: {}'.format(len(raw_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Read saved list of data from object into a dataframe\n",
    "# raw_df = pd.read_pickle('DataSet/data_07-10-18.pkl')\n",
    "# print(len(raw_df))\n",
    "# raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_width = len(raw_df['data'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out key counts less than threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "key_count = collections.Counter(raw_df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 0.5 # Bar width\n",
    "figsize = (15, 4)\n",
    "\n",
    "def plot_key_hist(most_common):\n",
    "    if len(most_common) > 30:\n",
    "        most_common = most_common[:30]\n",
    "        \n",
    "    hist_labels, hist_values = zip(*most_common) # Show only a subset of all keys\n",
    "    indexes = np.arange(len(hist_labels))\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(indexes, hist_values, width)\n",
    "    plt.xticks(indexes + width * 0.5, hist_labels, rotation='vertical')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEnCAYAAAAKIrrIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGO4kSZIkaQAMd5IkSZI0AP8fzgD5KXoQ2EsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1506e9fdbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_key_hist(key_count.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Counter.most_common of Counter({'space': 5072, 'e': 3128, 't': 2451, 'a': 2167, 'i': 1883, 'o': 1802, 'n': 1790, 's': 1776, 'r': 1508, 'h': 1126, 'l': 1122, 'd': 894, 'c': 849, 'u': 641, 'm': 633, 'g': 596, 'f': 525, 'p': 488, 'w': 439, 'y': 432, 'b': 395, 'v': 318, 'backspace': 309, '.': 288, ',': 251, 'k': 193, 'enter': 150, 'shift': 120, 'x': 108, \"'\": 77, '0': 72, 'z': 67, 'ctrl_l': 60, '-': 56, '1': 45, '2': 43, 'q': 42, 'delete': 38, 'down': 38, '9': 35, 'j': 27, '3': 25, '5': 21, 'esc': 17, '/': 17, ';': 16, 'left': 16, '7': 15, '6': 14, '8': 14, '4': 14, 'up': 10, 'right': 8, 'tab': 4, '=': 4, '`': 1})>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_count.most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Data Size: 14208, Class Count: 8, Threshold: 1775\n"
     ]
    }
   ],
   "source": [
    "# Maximize DataSet Size By Finding Optimal Threshold\n",
    "max_data_size = 0\n",
    "max_class_cnt = 0\n",
    "threshold_max = 0\n",
    "for _, v in key_count.most_common():\n",
    "    threshold = v - 1\n",
    "    min_thresh_cnts = [count for key, count in zip(key_count.keys(), key_count.values()) if count > threshold]\n",
    "    class_cnt = len(min_thresh_cnts)\n",
    "    data_size = min(min_thresh_cnts)*len(min_thresh_cnts)\n",
    "    if data_size > max_data_size:\n",
    "        max_data_size = data_size\n",
    "        max_class_cnt = class_cnt\n",
    "        threshold_max = threshold\n",
    "print('Max Data Size: {}, Class Count: {}, Threshold: {}'.format(max_data_size, max_class_cnt, threshold_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get list of keys with counts greater than threshold\n",
    "threshold = threshold_max\n",
    "min_thresh_keys = [key for key, count in zip(key_count.keys(), key_count.values()) if count > threshold]\n",
    "\n",
    "# Save list of key classes to pickle\n",
    "pickle.dump(min_thresh_keys, open(os.path.join(dataset_dir, \"key_classes.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_thresh_df = raw_df[raw_df['key'].isin(min_thresh_keys)] # Filter dataframe to only include keys > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_max_thresh(grouped_class):\n",
    "    return grouped_class.sample(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep same number of samples in each class by throwing away everything past the threshold\n",
    "df = min_thresh_df.groupby(['key']).apply(trim_max_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot truncated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truncated_count = collections.Counter(df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEPCAYAAADh3T2TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1506dedb6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_key_hist(truncated_count.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip to Load If Normalized Data Already Exists on Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = df['data'].values\n",
    "input_data = np.stack(input_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stephen\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int16 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "normalized_data = scaler.fit_transform(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = len(set(df['key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_str = [str(key) for key in df['key']]\n",
    "lb = preprocessing.LabelBinarizer() # Create encoder\n",
    "lb.fit(list(set(labels_str)))\n",
    "labels = lb.transform(labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'e', 'i', 'n', 'o', 's', 'space', 't'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Training and Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape to add 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14200, 10240, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data = normalized_data.reshape((normalized_data.shape[0], normalized_data.shape[1], 1))\n",
    "# labels = labels.reshape((labels.shape[0], labels.shape[1], 1))\n",
    "normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    normalized_data, \n",
    "    labels, \n",
    "    test_size=0.1, \n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs(data_width, n_classes):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    :param data_width: The total number of samples in the recorded data point\n",
    "    :param n_classes: Number of Classes\n",
    "    :return: Tuple of (tensor of input audio data, key press labels, learning rate, keep_prob)\n",
    "    \"\"\"\n",
    "    # TODO: Add audio channels to input\n",
    "    \n",
    "    with tf.name_scope(\"Inputs\"):\n",
    "        audio_inputs = tf.placeholder(tf.float32, [None, data_width, 1], name='inputs')\n",
    "    with tf.name_scope(\"Targets\"):\n",
    "        key_labels = tf.placeholder(tf.float32, [None, n_classes], name='labels')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_probability')\n",
    "\n",
    "    return audio_inputs, key_labels, learning_rate, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(X, keep_prob, n_classes):\n",
    "    \"\"\"\n",
    "    Create the network\n",
    "    :param X: Tensor of input recording(s)\n",
    "    :param keep_prob: Tensor for the keep probability\n",
    "    :param n_classes: Number of Classes\n",
    "    :return: Tuple of (tensor output of the classifier, tensor logits of the classifier)\n",
    "    \"\"\"    \n",
    "    # Hyperparameters\n",
    "    alpha = 0.2\n",
    "    h_dim = 32\n",
    "    \n",
    "    #print(\"X: {}\".format(X.shape))\n",
    "     \n",
    "    with tf.name_scope(\"Hidden_Layer1\"):\n",
    "        #h1 = tf.layers.dense(X, h_dim, activation=None)\n",
    "        h1 = tf.layers.conv1d(X, h_dim, 200, 10, 'same', activation=None)\n",
    "        h1 = tf.layers.max_pooling1d(h1, 5, 2, 'same')\n",
    "        h1 = tf.nn.dropout(h1, keep_prob) # Regularization\n",
    "        h1 = tf.maximum(h1*alpha, h1) # Leaky ReLu\n",
    "        h1 = tf.layers.batch_normalization(h1)\n",
    "        \n",
    "    #print(\"h1: {}\".format(h1.shape))\n",
    "\n",
    "    with tf.name_scope(\"Hidden_Layer2\"):\n",
    "        #h2 = tf.layers.dense(h1, h_dim, activation=None)\n",
    "        h2 = tf.layers.conv1d(h1, h_dim*2, 50, 5, 'same', activation=None)\n",
    "        #h2 = tf.layers.maxpool2d(h2, 5, 2, 'same')\n",
    "        h2 = tf.nn.dropout(h2, keep_prob) # Regularization        \n",
    "        h2 = tf.maximum(h2*alpha, h2) # Leaky ReLu\n",
    "        h2 = tf.layers.batch_normalization(h2)\n",
    "        \n",
    "    #print(\"h2: {}\".format(h2.shape))\n",
    "\n",
    "    with tf.name_scope(\"Hidden_Layer3\"):\n",
    "        #h3 = tf.layers.dense(h2, h_dim, activation=None)\n",
    "        h3 = tf.layers.conv1d(h2, h_dim*3, 20, 2, 'same', activation=None)\n",
    "        #h3 = tf.layers.maxpool2d(h3, 3, 2, 'same')\n",
    "        h3 = tf.nn.dropout(h3, keep_prob) # Regularization\n",
    "        h3 = tf.maximum(h3*alpha, h3) # Leaky ReLu\n",
    "        h3 = tf.layers.batch_normalization(h3)\n",
    "        \n",
    "    with tf.name_scope(\"Hidden_Layer4\"):\n",
    "        h4 = tf.layers.conv1d(h3, h_dim*4, 10, 1, 'same', activation=None)\n",
    "        h4 = tf.nn.dropout(h4, keep_prob) # Regularization\n",
    "        h4 = tf.maximum(h4*alpha, h4) # Leaky ReLu\n",
    "        h4 = tf.layers.batch_normalization(h4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.name_scope(\"Output\"):\n",
    "        flat_dim = int(h4.get_shape()[1])*int(h4.get_shape()[2])\n",
    "        flat = tf.reshape(h4, [-1, flat_dim])\n",
    "        #print(\"flat: {}\".format(flat.shape))\n",
    "        logits = tf.layers.dense(flat, n_classes, activation=None, name='logits')\n",
    "        #print(\"logits: {}\".format(logits.shape))\n",
    "        #out = tf.nn.softmax(logits, name='softmax_out')\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy, esi):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    : esi: Epochs since the last improvement\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Validation_Stats\"):\n",
    "        validation_loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "        validation_accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "        train_accuracy = session.run(accuracy, feed_dict={x: train_features[:1000], y: train_labels[:1000], keep_prob: 1.0})\n",
    "        print(\"Train Accuracy: {0:0.4f}, Validation Accuracy: {1:0.4f}, Validation Loss: {2:0.4f}, ESI: {3}\".format(train_accuracy, validation_accuracy, validation_loss, esi))\n",
    "        return validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x, y, learn_rate, keep_prob = model_inputs(data_width, n_classes)\n",
    "\n",
    "#Model\n",
    "logits = network(x, keep_prob, n_classes)\n",
    "\n",
    "with tf.name_scope(\"Cost\"):\n",
    "    # Cost and Optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y, name='loss'), name='cost')\n",
    "    \n",
    "with tf.name_scope(\"Train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate, name='optimizer').minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1), name='prediction')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    \n",
    "predicted = tf.nn.softmax(logits, name='predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the graph for TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_writer = tf.summary.FileWriter('./logs/2', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 16\n",
    "keep_probability = 0.70\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy to beat (Min of 3 classes)\n",
    "print(\"{:.3}%\".format((1/n_classes)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Accuracy: 0.1310, Validation Accuracy: 0.1120, Validation Loss: 2.1193, ESI: 0\n",
      "Epoch 1: Train Accuracy: 0.2130, Validation Accuracy: 0.2106, Validation Loss: 1.8059, ESI: 0\n",
      "Epoch 2: Train Accuracy: 0.2750, Validation Accuracy: 0.2563, Validation Loss: 1.6417, ESI: 0\n",
      "Epoch 3: Train Accuracy: 0.4640, Validation Accuracy: 0.4775, Validation Loss: 1.4168, ESI: 0\n",
      "Epoch 4: Train Accuracy: 0.5160, Validation Accuracy: 0.5085, Validation Loss: 1.2052, ESI: 0\n",
      "Epoch 5: Train Accuracy: 0.5410, Validation Accuracy: 0.5303, Validation Loss: 1.1013, ESI: 0\n",
      "Epoch 6: Train Accuracy: 0.5570, Validation Accuracy: 0.5437, Validation Loss: 1.0568, ESI: 0\n",
      "Epoch 7: Train Accuracy: 0.5770, Validation Accuracy: 0.5697, Validation Loss: 1.0060, ESI: 0\n",
      "Epoch 8: Train Accuracy: 0.5840, Validation Accuracy: 0.5704, Validation Loss: 0.9793, ESI: 0\n",
      "Epoch 9: Train Accuracy: 0.5930, Validation Accuracy: 0.5746, Validation Loss: 0.9979, ESI: 0\n",
      "Epoch 10: Train Accuracy: 0.5960, Validation Accuracy: 0.5697, Validation Loss: 0.9104, ESI: 0\n",
      "Epoch 11: Train Accuracy: 0.6040, Validation Accuracy: 0.5944, Validation Loss: 0.8624, ESI: 1\n",
      "Epoch 12: Train Accuracy: 0.6250, Validation Accuracy: 0.6056, Validation Loss: 0.8769, ESI: 0\n",
      "Epoch 13: Train Accuracy: 0.6350, Validation Accuracy: 0.6141, Validation Loss: 0.8198, ESI: 0\n",
      "Epoch 14: Train Accuracy: 0.6540, Validation Accuracy: 0.6190, Validation Loss: 0.7637, ESI: 0\n",
      "Epoch 15: Train Accuracy: 0.6810, Validation Accuracy: 0.6380, Validation Loss: 0.7398, ESI: 0\n",
      "Epoch 16: Train Accuracy: 0.6960, Validation Accuracy: 0.6437, Validation Loss: 0.7773, ESI: 0\n",
      "Epoch 17: Train Accuracy: 0.7110, Validation Accuracy: 0.6641, Validation Loss: 0.7632, ESI: 0\n",
      "Epoch 18: Train Accuracy: 0.6950, Validation Accuracy: 0.6479, Validation Loss: 0.7544, ESI: 0\n",
      "Epoch 19: Train Accuracy: 0.7250, Validation Accuracy: 0.6669, Validation Loss: 0.6766, ESI: 1\n",
      "Epoch 20: Train Accuracy: 0.7360, Validation Accuracy: 0.6746, Validation Loss: 0.6473, ESI: 0\n",
      "Epoch 21: Train Accuracy: 0.7480, Validation Accuracy: 0.6796, Validation Loss: 0.5828, ESI: 0\n",
      "Epoch 22: Train Accuracy: 0.7600, Validation Accuracy: 0.6930, Validation Loss: 0.4925, ESI: 0\n",
      "Epoch 23: Train Accuracy: 0.7770, Validation Accuracy: 0.6887, Validation Loss: 0.5682, ESI: 0\n",
      "Epoch 24: Train Accuracy: 0.7710, Validation Accuracy: 0.6859, Validation Loss: 0.4973, ESI: 1\n",
      "Epoch 25: Train Accuracy: 0.7850, Validation Accuracy: 0.7113, Validation Loss: 0.4350, ESI: 2\n",
      "Epoch 26: Train Accuracy: 0.7920, Validation Accuracy: 0.7077, Validation Loss: 0.4413, ESI: 0\n",
      "Epoch 27: Train Accuracy: 0.7880, Validation Accuracy: 0.7077, Validation Loss: 0.3737, ESI: 1\n",
      "Epoch 28: Train Accuracy: 0.8080, Validation Accuracy: 0.7197, Validation Loss: 0.5061, ESI: 2\n",
      "Epoch 29: Train Accuracy: 0.8050, Validation Accuracy: 0.7225, Validation Loss: 0.4176, ESI: 0\n",
      "Epoch 30: Train Accuracy: 0.8070, Validation Accuracy: 0.7106, Validation Loss: 0.4342, ESI: 0\n",
      "Epoch 31: Train Accuracy: 0.8210, Validation Accuracy: 0.7254, Validation Loss: 0.3907, ESI: 1\n",
      "Epoch 32: Train Accuracy: 0.8170, Validation Accuracy: 0.7246, Validation Loss: 0.4073, ESI: 0\n",
      "Epoch 33: Train Accuracy: 0.8240, Validation Accuracy: 0.7190, Validation Loss: 0.3035, ESI: 1\n",
      "Epoch 34: Train Accuracy: 0.8270, Validation Accuracy: 0.7268, Validation Loss: 0.3108, ESI: 2\n",
      "Epoch 35: Train Accuracy: 0.8280, Validation Accuracy: 0.7218, Validation Loss: 0.4148, ESI: 0\n",
      "Epoch 36: Train Accuracy: 0.8390, Validation Accuracy: 0.7444, Validation Loss: 0.2710, ESI: 1\n",
      "Epoch 37: Train Accuracy: 0.8450, Validation Accuracy: 0.7430, Validation Loss: 0.3705, ESI: 0\n",
      "Epoch 38: Train Accuracy: 0.8410, Validation Accuracy: 0.7352, Validation Loss: 0.3495, ESI: 1\n",
      "Epoch 39: Train Accuracy: 0.8530, Validation Accuracy: 0.7430, Validation Loss: 0.3715, ESI: 2\n",
      "Epoch 40: Train Accuracy: 0.8460, Validation Accuracy: 0.7465, Validation Loss: 0.3708, ESI: 3\n",
      "Epoch 41: Train Accuracy: 0.8540, Validation Accuracy: 0.7514, Validation Loss: 0.2551, ESI: 0\n",
      "Epoch 42: Train Accuracy: 0.8490, Validation Accuracy: 0.7493, Validation Loss: 0.2539, ESI: 0\n",
      "Epoch 43: Train Accuracy: 0.8510, Validation Accuracy: 0.7444, Validation Loss: 0.3007, ESI: 1\n",
      "Epoch 44: Train Accuracy: 0.8540, Validation Accuracy: 0.7408, Validation Loss: 0.2724, ESI: 2\n",
      "Epoch 45: Train Accuracy: 0.8620, Validation Accuracy: 0.7437, Validation Loss: 0.2036, ESI: 3\n",
      "Epoch 46: Train Accuracy: 0.8610, Validation Accuracy: 0.7366, Validation Loss: 0.2820, ESI: 4\n",
      "Epoch 47: Train Accuracy: 0.8670, Validation Accuracy: 0.7542, Validation Loss: 0.1785, ESI: 5\n",
      "Epoch 48: Train Accuracy: 0.8610, Validation Accuracy: 0.7408, Validation Loss: 0.2437, ESI: 0\n",
      "Epoch 49: Train Accuracy: 0.8680, Validation Accuracy: 0.7387, Validation Loss: 0.2184, ESI: 1\n",
      "Epoch 50: Train Accuracy: 0.8740, Validation Accuracy: 0.7556, Validation Loss: 0.2163, ESI: 2\n",
      "Epoch 51: Train Accuracy: 0.8720, Validation Accuracy: 0.7345, Validation Loss: 0.2422, ESI: 0\n",
      "Epoch 52: Train Accuracy: 0.8730, Validation Accuracy: 0.7458, Validation Loss: 0.1570, ESI: 1\n",
      "Epoch 53: Train Accuracy: 0.8850, Validation Accuracy: 0.7613, Validation Loss: 0.1742, ESI: 2\n",
      "Epoch 54: Train Accuracy: 0.8840, Validation Accuracy: 0.7528, Validation Loss: 0.1245, ESI: 0\n",
      "Epoch 55: Train Accuracy: 0.8840, Validation Accuracy: 0.7585, Validation Loss: 0.1835, ESI: 1\n",
      "Epoch 56: Train Accuracy: 0.9000, Validation Accuracy: 0.7634, Validation Loss: 0.1858, ESI: 2\n",
      "Epoch 57: Train Accuracy: 0.8890, Validation Accuracy: 0.7570, Validation Loss: 0.1421, ESI: 0\n",
      "Epoch 58: Train Accuracy: 0.8950, Validation Accuracy: 0.7683, Validation Loss: 0.1451, ESI: 1\n",
      "Epoch 59: Train Accuracy: 0.8890, Validation Accuracy: 0.7486, Validation Loss: 0.1991, ESI: 0\n",
      "Epoch 60: Train Accuracy: 0.8960, Validation Accuracy: 0.7648, Validation Loss: 0.1814, ESI: 1\n",
      "Epoch 61: Train Accuracy: 0.8980, Validation Accuracy: 0.7641, Validation Loss: 0.2109, ESI: 2\n",
      "Epoch 62: Train Accuracy: 0.8840, Validation Accuracy: 0.7542, Validation Loss: 0.1369, ESI: 3\n",
      "Epoch 63: Train Accuracy: 0.9030, Validation Accuracy: 0.7669, Validation Loss: 0.1359, ESI: 4\n",
      "Epoch 64: Train Accuracy: 0.9020, Validation Accuracy: 0.7641, Validation Loss: 0.1520, ESI: 5\n",
      "Epoch 65: Train Accuracy: 0.9060, Validation Accuracy: 0.7662, Validation Loss: 0.1043, ESI: 6\n",
      "Epoch 66: Train Accuracy: 0.8960, Validation Accuracy: 0.7648, Validation Loss: 0.1110, ESI: 7\n",
      "Epoch 67: Train Accuracy: 0.9060, Validation Accuracy: 0.7662, Validation Loss: 0.1517, ESI: 8\n",
      "Epoch 68: Train Accuracy: 0.9160, Validation Accuracy: 0.7761, Validation Loss: 0.1688, ESI: 9\n",
      "Epoch 69: Train Accuracy: 0.9170, Validation Accuracy: 0.7824, Validation Loss: 0.0725, ESI: 0\n",
      "Epoch 70: Train Accuracy: 0.9150, Validation Accuracy: 0.7648, Validation Loss: 0.0984, ESI: 0\n",
      "Epoch 71: Train Accuracy: 0.9210, Validation Accuracy: 0.7796, Validation Loss: 0.0855, ESI: 1\n",
      "Epoch 72: Train Accuracy: 0.9220, Validation Accuracy: 0.7690, Validation Loss: 0.0945, ESI: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-672a6bc189c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                                            \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                            \u001b[0mlearn_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                            keep_prob: keep_probability})\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {}: '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_validation_accuracy = 0.0\n",
    "epochs_since_improvement = 0\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in get_batches(train_features, train_labels, batch_size):\n",
    "            sess.run(optimizer, feed_dict={x: batch_features, \n",
    "                                           y: batch_labels, \n",
    "                                           learn_rate: learning_rate, \n",
    "                                           keep_prob: keep_probability})\n",
    "        if epoch % 1 == 0:\n",
    "            print('Epoch {}: '.format(epoch), end='')\n",
    "            validation_accuracy = print_stats(sess, batch_features, batch_labels, cost, accuracy, epochs_since_improvement)         \n",
    "        \n",
    "            if validation_accuracy > max_validation_accuracy:\n",
    "                max_validation_accuracy = validation_accuracy\n",
    "                epochs_since_improvement = 0\n",
    "                saver.save(sess, \"checkpoints/model.ckpt\")\n",
    "            else:\n",
    "                epochs_since_improvement += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_pickle(os.path.join(dataset_dir, \"test_set.pkl\"))\n",
    "min_thresh_keys = pickle.load(open(os.path.join(dataset_dir, \"key_classes.p\"), \"rb\"))\n",
    "test_set = test_set[test_set['key'].isin(min_thresh_keys)] # Filter dataframe to only include keys > threshold\n",
    "\n",
    "data_width = len(test_set['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stephen\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int16 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Append training data to test_set for more accurate normalization\n",
    "ts_len = len(test_set)\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith(\".pkl\"): \n",
    "        df = pd.read_pickle(os.path.join(dataset_dir, filename))\n",
    "        break\n",
    "\n",
    "test_set.append(df, ignore_index=True)\n",
    "\n",
    "input_data = test_set['data'].values\n",
    "input_data = np.stack(input_data, axis=0)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "normalized_data = scaler.fit_transform(input_data)\n",
    "normalized_data = normalized_data[:ts_len]\n",
    "\n",
    "normalized_data = normalized_data.reshape((normalized_data.shape[0], normalized_data.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "loader = tf.train.import_meta_graph('checkpoints/model.ckpt.meta')\n",
    "with tf.Session() as sess:\n",
    "    loader.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    x = graph.get_tensor_by_name(\"Inputs/inputs:0\")\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_probability:0\")\n",
    "    predicted = graph.get_tensor_by_name(\"predicted:0\")\n",
    "    \n",
    "    feed_dict = {x: normalized_data, keep_prob: 1.0}\n",
    "    prediction = sess.run(predicted, feed_dict=feed_dict).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['key'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 1.00\n",
      "Key: n, Prediction: n, Probability: 0.99\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: s, Prediction: space, Probability: 0.99\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: s, Probability: 0.52\n",
      "Key: s, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.96\n",
      "Key: e, Prediction: e, Probability: 0.42\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: e, Probability: 0.96\n",
      "Key: e, Prediction: n, Probability: 0.90\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: t, Prediction: space, Probability: 0.99\n",
      "Key: i, Prediction: i, Probability: 1.00\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: a, Probability: 0.70\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 0.95\n",
      "Key: t, Prediction: n, Probability: 0.94\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 0.78\n",
      "Key: e, Prediction: n, Probability: 0.50\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: n, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: o, Probability: 0.55\n",
      "Key: s, Prediction: s, Probability: 0.61\n",
      "Key: t, Prediction: i, Probability: 0.97\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.72\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 0.37\n",
      "Key: n, Prediction: n, Probability: 0.90\n",
      "Key: t, Prediction: e, Probability: 0.51\n",
      "Key: s, Prediction: e, Probability: 0.76\n",
      "Key: a, Prediction: a, Probability: 0.70\n",
      "Key: s, Prediction: e, Probability: 0.68\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: e, Probability: 0.85\n",
      "Key: e, Prediction: n, Probability: 0.97\n",
      "Key: s, Prediction: s, Probability: 1.00\n",
      "Key: a, Prediction: e, Probability: 0.96\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: i, Probability: 0.88\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: n, Probability: 0.34\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: space, Probability: 0.98\n",
      "Key: o, Prediction: o, Probability: 1.00\n",
      "Key: a, Prediction: i, Probability: 0.91\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: e, Probability: 0.94\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: s, Prediction: e, Probability: 1.00\n",
      "Key: i, Prediction: i, Probability: 1.00\n",
      "Key: o, Prediction: n, Probability: 0.70\n",
      "Key: s, Prediction: s, Probability: 0.58\n",
      "Key: e, Prediction: space, Probability: 0.62\n",
      "Key: space, Prediction: e, Probability: 0.97\n",
      "Key: e, Prediction: e, Probability: 0.99\n",
      "Key: a, Prediction: e, Probability: 0.44\n",
      "Key: i, Prediction: i, Probability: 0.99\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: e, Prediction: n, Probability: 0.88\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: i, Probability: 0.72\n",
      "Key: o, Prediction: o, Probability: 0.94\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: o, Probability: 0.49\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 0.97\n",
      "Key: e, Prediction: n, Probability: 0.51\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: space, Probability: 0.64\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: t, Prediction: a, Probability: 0.92\n",
      "Key: i, Prediction: i, Probability: 0.94\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: s, Prediction: e, Probability: 0.72\n",
      "Key: e, Prediction: e, Probability: 0.93\n",
      "Key: a, Prediction: space, Probability: 0.98\n",
      "Key: n, Prediction: n, Probability: 0.99\n",
      "Key: s, Prediction: o, Probability: 0.88\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: i, Probability: 1.00\n",
      "Key: n, Prediction: n, Probability: 0.99\n",
      "Key: space, Prediction: space, Probability: 0.94\n",
      "Key: a, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.51\n",
      "Key: e, Prediction: e, Probability: 0.98\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: i, Probability: 0.77\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 0.95\n",
      "Key: i, Prediction: i, Probability: 0.60\n",
      "Key: e, Prediction: n, Probability: 0.98\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: n, Probability: 0.50\n",
      "Key: e, Prediction: e, Probability: 0.53\n",
      "Key: t, Prediction: space, Probability: 0.71\n",
      "Key: i, Prediction: i, Probability: 0.93\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: e, Probability: 0.90\n",
      "Key: s, Prediction: n, Probability: 0.96\n",
      "Key: e, Prediction: space, Probability: 0.65\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 1.00\n",
      "Key: t, Prediction: e, Probability: 0.79\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: e, Probability: 0.98\n",
      "Key: a, Prediction: e, Probability: 0.67\n",
      "Key: i, Prediction: i, Probability: 0.95\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: s, Prediction: n, Probability: 0.93\n",
      "Key: t, Prediction: o, Probability: 0.88\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: e, Probability: 0.89\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: i, Probability: 0.90\n",
      "Key: e, Prediction: o, Probability: 0.75\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: i, Probability: 0.66\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 0.99\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.78\n",
      "Key: o, Prediction: i, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.90\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: a, Probability: 0.62\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: o, Probability: 0.67\n",
      "Key: o, Prediction: o, Probability: 0.99\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: s, Prediction: e, Probability: 0.97\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.94\n",
      "Key: space, Prediction: space, Probability: 0.97\n",
      "Key: a, Prediction: a, Probability: 0.53\n",
      "Key: s, Prediction: s, Probability: 0.80\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: n, Probability: 0.99\n",
      "Key: s, Prediction: e, Probability: 0.94\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: i, Probability: 0.96\n",
      "Key: a, Prediction: e, Probability: 0.58\n",
      "Key: n, Prediction: n, Probability: 0.98\n",
      "Key: s, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.63\n",
      "Key: t, Prediction: i, Probability: 0.40\n",
      "Key: a, Prediction: e, Probability: 1.00\n",
      "Key: t, Prediction: i, Probability: 0.96\n",
      "Key: o, Prediction: n, Probability: 0.97\n",
      "Key: s, Prediction: i, Probability: 0.58\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 0.47\n",
      "Key: n, Prediction: i, Probability: 0.54\n",
      "Key: a, Prediction: e, Probability: 0.95\n",
      "Key: i, Prediction: i, Probability: 0.88\n",
      "Key: s, Prediction: e, Probability: 0.76\n",
      "Key: t, Prediction: n, Probability: 0.66\n",
      "Key: s, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: a, Probability: 0.98\n",
      "Key: space, Prediction: n, Probability: 0.86\n",
      "Key: s, Prediction: e, Probability: 0.91\n",
      "Key: t, Prediction: n, Probability: 0.41\n",
      "Key: e, Prediction: n, Probability: 0.87\n",
      "Key: e, Prediction: e, Probability: 0.98\n",
      "Key: t, Prediction: e, Probability: 0.81\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: e, Probability: 0.91\n",
      "Key: n, Prediction: n, Probability: 0.99\n",
      "Key: a, Prediction: e, Probability: 1.00\n",
      "Key: s, Prediction: space, Probability: 0.69\n",
      "Key: t, Prediction: n, Probability: 0.91\n",
      "Key: s, Prediction: e, Probability: 0.62\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: s, Prediction: s, Probability: 0.46\n",
      "Key: o, Prediction: o, Probability: 0.63\n",
      "Key: t, Prediction: o, Probability: 0.64\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: s, Prediction: e, Probability: 0.92\n",
      "Key: e, Prediction: e, Probability: 0.99\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: s, Prediction: space, Probability: 0.60\n",
      "Key: space, Prediction: space, Probability: 0.56\n",
      "Key: a, Prediction: e, Probability: 0.91\n",
      "Key: o, Prediction: n, Probability: 0.49\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: i, Prediction: n, Probability: 0.94\n",
      "Key: o, Prediction: o, Probability: 0.96\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: s, Prediction: n, Probability: 0.79\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: s, Probability: 0.45\n",
      "Key: n, Prediction: i, Probability: 0.85\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: space, Probability: 0.65\n",
      "Key: e, Prediction: space, Probability: 0.53\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.98\n",
      "Key: e, Prediction: e, Probability: 0.99\n",
      "Key: a, Prediction: e, Probability: 0.53\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: a, Probability: 0.99\n",
      "Key: s, Prediction: e, Probability: 0.93\n",
      "Key: s, Prediction: space, Probability: 0.41\n",
      "Key: a, Prediction: n, Probability: 0.71\n",
      "Key: e, Prediction: e, Probability: 0.87\n",
      "Key: t, Prediction: n, Probability: 0.56\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: i, Probability: 1.00\n",
      "Key: n, Prediction: i, Probability: 0.51\n",
      "Key: e, Prediction: space, Probability: 0.74\n",
      "Key: s, Prediction: n, Probability: 0.62\n",
      "Key: t, Prediction: n, Probability: 0.83\n",
      "Key: i, Prediction: i, Probability: 0.99\n",
      "Key: a, Prediction: a, Probability: 0.91\n",
      "Key: t, Prediction: n, Probability: 0.91\n",
      "Key: o, Prediction: o, Probability: 0.97\n",
      "Key: s, Prediction: e, Probability: 0.46\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: i, Probability: 0.95\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 0.90\n",
      "Key: t, Prediction: n, Probability: 0.43\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: s, Prediction: e, Probability: 0.99\n",
      "Key: e, Prediction: e, Probability: 0.99\n",
      "Key: e, Prediction: n, Probability: 0.67\n",
      "Key: s, Prediction: s, Probability: 0.91\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 1.00\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: t, Probability: 0.84\n",
      "Key: e, Prediction: space, Probability: 0.98\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: space, Probability: 0.93\n",
      "Key: e, Prediction: e, Probability: 0.86\n",
      "Key: i, Prediction: i, Probability: 0.98\n",
      "Key: i, Prediction: i, Probability: 1.00\n",
      "Key: n, Prediction: n, Probability: 0.98\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: e, Probability: 0.44\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 0.91\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: i, Probability: 0.95\n",
      "Key: s, Prediction: e, Probability: 0.99\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 1.00\n",
      "Key: i, Prediction: i, Probability: 0.98\n",
      "Key: i, Prediction: i, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: n, Probability: 0.92\n",
      "Key: i, Prediction: i, Probability: 1.00\n",
      "Key: t, Prediction: n, Probability: 0.98\n",
      "Key: t, Prediction: i, Probability: 0.96\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: o, Prediction: i, Probability: 0.98\n",
      "Key: t, Prediction: e, Probability: 0.82\n",
      "Key: t, Prediction: o, Probability: 0.95\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: e, Prediction: o, Probability: 0.73\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: o, Prediction: o, Probability: 0.46\n",
      "Key: s, Prediction: e, Probability: 0.82\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: n, Probability: 0.85\n",
      "Key: t, Prediction: n, Probability: 0.87\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: e, Prediction: n, Probability: 0.57\n",
      "Key: e, Prediction: space, Probability: 0.50\n",
      "Key: s, Prediction: s, Probability: 0.93\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: n, Probability: 0.96\n",
      "Key: o, Prediction: o, Probability: 0.98\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: s, Prediction: o, Probability: 0.99\n",
      "Key: t, Prediction: n, Probability: 0.99\n",
      "Key: o, Prediction: i, Probability: 0.64\n",
      "Key: i, Prediction: n, Probability: 0.52\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: a, Probability: 0.85\n",
      "Key: e, Prediction: e, Probability: 0.90\n",
      "Key: space, Prediction: space, Probability: 0.97\n",
      "Key: a, Prediction: e, Probability: 0.69\n",
      "Key: e, Prediction: e, Probability: 0.97\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: t, Prediction: e, Probability: 0.87\n",
      "Key: e, Prediction: e, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: i, Prediction: i, Probability: 0.48\n",
      "Key: s, Prediction: s, Probability: 0.93\n",
      "Key: t, Prediction: n, Probability: 1.00\n",
      "Key: a, Prediction: e, Probability: 0.93\n",
      "Key: e, Prediction: e, Probability: 0.86\n",
      "Key: n, Prediction: n, Probability: 1.00\n",
      "Key: space, Prediction: space, Probability: 1.00\n",
      "Key: a, Prediction: n, Probability: 0.92\n",
      "Key: s, Prediction: e, Probability: 0.97\n",
      "Accuracy: 0.595679012345679\n"
     ]
    }
   ],
   "source": [
    "correct_cnt = 0\n",
    "for i, r in enumerate(prediction):\n",
    "    actual_key = test_set['key'].values[i]\n",
    "    pred_key = lb.classes_[np.argmax(r)]\n",
    "    print('Key: {0}, Prediction: {1}, Probability: {2:0.2f}'.format(actual_key, pred_key, r[np.argmax(r)]))\n",
    "    if actual_key == pred_key:\n",
    "        correct_cnt += 1\n",
    "print('Accuracy: {}'.format(correct_cnt/len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
