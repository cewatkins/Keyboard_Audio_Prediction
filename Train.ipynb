{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Version of TensorFlow and Access to GPU\n",
    "This will check to make sure you have the correct version of TensorFlow and access to a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo List\n",
    "- Save normalized data so it doesn't need to be normalized each time\n",
    "- Batch norm after ReLu\n",
    "- Dense layers instead of CNNs\n",
    "- Add several dense layers after convolutional layers\n",
    "- Shuffle dataset\n",
    "- Play with learning rate and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.1.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_dir = 'DataSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: DataSet/2018-07-13_18-39-56_0.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-43-51_0.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-46-04_1.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-47-58_2.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-49-54_3.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-52-16_4.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-54-29_5.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-56-38_6.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_18-58-30_7.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-00-21_8.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-02-36_9.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-04-42_10.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-06-38_11.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-08-49_12.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-10-48_13.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-12-43_14.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-14-54_15.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-16-54_16.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-19-01_17.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-20-48_18.pkl, DataSet Length: 500\n",
      "File: DataSet/2018-07-13_19-22-54_19.pkl, DataSet Length: 500\n",
      "File: DataSet/data_07-08-18.pkl, DataSet Length: 7150\n",
      "File: DataSet/data_07-10-18_work.pkl, DataSet Length: 8700\n",
      "File: DataSet/data_07-13-18.pkl, DataSet Length: 5400\n",
      "Total Length: 31750\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith(\".pkl\"): \n",
    "        df = pd.read_pickle(os.path.join(dataset_dir, filename))\n",
    "        \n",
    "        if count == 0:\n",
    "            raw_df = df\n",
    "        else:\n",
    "            raw_df = raw_df.append(df, ignore_index=True)\n",
    "            \n",
    "        print('File: {}, DataSet Length: {}'.format(os.path.join(dataset_dir, filename), len(df)))\n",
    "        count += 1\n",
    "    else:\n",
    "        continue\n",
    "print('Total Length: {}'.format(len(raw_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Read saved list of data from object into a dataframe\n",
    "# raw_df = pd.read_pickle('DataSet/data_07-10-18.pkl')\n",
    "# print(len(raw_df))\n",
    "# raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_width = len(raw_df['data'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out key counts less than threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "key_count = collections.Counter(raw_df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 0.5 # Bar width\n",
    "figsize = (15, 4)\n",
    "\n",
    "def plot_key_hist(most_common):\n",
    "    if len(most_common) > 30:\n",
    "        most_common = most_common[:30]\n",
    "        \n",
    "    hist_labels, hist_values = zip(*most_common) # Show only a subset of all keys\n",
    "    indexes = np.arange(len(hist_labels))\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(indexes, hist_values, width)\n",
    "    plt.xticks(indexes + width * 0.5, hist_labels, rotation='vertical')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEnCAYAAAAKIrrIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIY7SZIkSRoAw50kSZIkDcD/B7kF+cRN5MNvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e17dac8198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_key_hist(key_count.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Counter.most_common of Counter({'space': 4990, 'e': 3070, 't': 2414, 'a': 2135, 'i': 1858, 'o': 1774, 'n': 1766, 's': 1738, 'r': 1490, 'h': 1109, 'l': 1102, 'd': 877, 'c': 837, 'u': 629, 'm': 623, 'g': 591, 'f': 517, 'p': 479, 'w': 431, 'y': 429, 'b': 392, 'v': 311, 'backspace': 309, '.': 283, ',': 246, 'k': 188, 'enter': 148, 'shift': 120, 'x': 107, \"'\": 76, '0': 69, 'z': 67, 'ctrl_l': 60, '-': 54, '1': 45, '2': 43, 'q': 42, 'down': 38, 'delete': 38, '9': 35, 'j': 26, '3': 24, '5': 20, '/': 17, 'esc': 17, 'left': 16, ';': 16, '7': 15, '8': 14, '6': 14, '4': 14, 'up': 10, 'right': 8, '=': 4, 'tab': 4, '`': 1})>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_count.most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Data Size: 13904, Class Count: 8, Threshold: 1737\n"
     ]
    }
   ],
   "source": [
    "# Maximize DataSet Size By Finding Optimal Threshold\n",
    "max_data_size = 0\n",
    "max_class_cnt = 0\n",
    "threshold_max = 0\n",
    "for _, v in key_count.most_common():\n",
    "    threshold = v - 1\n",
    "    min_thresh_cnts = [count for key, count in zip(key_count.keys(), key_count.values()) if count > threshold]\n",
    "    class_cnt = len(min_thresh_cnts)\n",
    "    data_size = min(min_thresh_cnts)*len(min_thresh_cnts)\n",
    "    if data_size > max_data_size:\n",
    "        max_data_size = data_size\n",
    "        max_class_cnt = class_cnt\n",
    "        threshold_max = threshold\n",
    "print('Max Data Size: {}, Class Count: {}, Threshold: {}'.format(max_data_size, max_class_cnt, threshold_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get list of keys with counts greater than threshold\n",
    "threshold = threshold_max\n",
    "min_thresh_keys = [key for key, count in zip(key_count.keys(), key_count.values()) if count > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_thresh_df = raw_df[raw_df['key'].isin(min_thresh_keys)] # Filter dataframe to only include keys > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_max_thresh(grouped_class):\n",
    "    return grouped_class.sample(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep same number of samples in each class by throwing away everything past the threshold\n",
    "df = min_thresh_df.groupby(['key']).apply(trim_max_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot truncated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truncated_count = collections.Counter(df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEPCAYAAADh3T2TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e18e922240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_key_hist(truncated_count.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip to Load If Normalized Data Already Exists on Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = df['data'].values\n",
    "input_data = np.stack(input_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stephen\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int16 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "normalized_data = scaler.fit_transform(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = len(set(df['key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_str = [str(key) for key in df['key']]\n",
    "lb = preprocessing.LabelBinarizer() # Create encoder\n",
    "lb.fit(list(set(labels_str)))\n",
    "labels = lb.transform(labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'e', 'i', 'n', 'o', 's', 'space', 't'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Training and Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape to add 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13896, 10240, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data = normalized_data.reshape((normalized_data.shape[0], normalized_data.shape[1], 1))\n",
    "# labels = labels.reshape((labels.shape[0], labels.shape[1], 1))\n",
    "normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    normalized_data, \n",
    "    labels, \n",
    "    test_size=0.1, \n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs(data_width, n_classes):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    :param data_width: The total number of samples in the recorded data point\n",
    "    :param n_classes: Number of Classes\n",
    "    :return: Tuple of (tensor of input audio data, key press labels, learning rate, keep_prob)\n",
    "    \"\"\"\n",
    "    # TODO: Add audio channels to input\n",
    "    \n",
    "    with tf.name_scope(\"Inputs\"):\n",
    "        audio_inputs = tf.placeholder(tf.float32, [None, data_width, 1], name='inputs')\n",
    "    with tf.name_scope(\"Targets\"):\n",
    "        key_labels = tf.placeholder(tf.float32, [None, n_classes], name='labels')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_probability')\n",
    "\n",
    "    return audio_inputs, key_labels, learning_rate, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(X, keep_prob, n_classes):\n",
    "    \"\"\"\n",
    "    Create the network\n",
    "    :param X: Tensor of input recording(s)\n",
    "    :param keep_prob: Tensor for the keep probability\n",
    "    :param n_classes: Number of Classes\n",
    "    :return: Tuple of (tensor output of the classifier, tensor logits of the classifier)\n",
    "    \"\"\"    \n",
    "    # Hyperparameters\n",
    "    alpha = 0.2\n",
    "    h_dim = 16\n",
    "    \n",
    "    #print(\"X: {}\".format(X.shape))\n",
    "     \n",
    "    with tf.name_scope(\"Hidden_Layer1\"):\n",
    "        #h1 = tf.layers.dense(X, h_dim, activation=None)\n",
    "        h1 = tf.layers.conv1d(X, h_dim, 100, 10, 'same', activation=None)\n",
    "        #h1 = tf.layers.maxpool2d(h1, 5, 2, 'same')\n",
    "        h1 = tf.nn.dropout(h1, keep_prob) # Regularization\n",
    "        h1 = tf.maximum(h1*alpha, h1) # Leaky ReLu\n",
    "        h1 = tf.layers.batch_normalization(h1)\n",
    "        \n",
    "    #print(\"h1: {}\".format(h1.shape))\n",
    "\n",
    "    with tf.name_scope(\"Hidden_Layer2\"):\n",
    "        #h2 = tf.layers.dense(h1, h_dim, activation=None)\n",
    "        h2 = tf.layers.conv1d(h1, h_dim*2, 50, 5, 'same', activation=None)\n",
    "        #h2 = tf.layers.maxpool2d(h2, 5, 2, 'same')\n",
    "        h2 = tf.nn.dropout(h2, keep_prob) # Regularization        \n",
    "        h2 = tf.maximum(h2*alpha, h2) # Leaky ReLu\n",
    "        h2 = tf.layers.batch_normalization(h2)\n",
    "        \n",
    "    #print(\"h2: {}\".format(h2.shape))\n",
    "\n",
    "    with tf.name_scope(\"Hidden_Layer3\"):\n",
    "        #h3 = tf.layers.dense(h2, h_dim, activation=None)\n",
    "        h3 = tf.layers.conv1d(h2, h_dim*3, 25, 2, 'same', activation=None)\n",
    "        #h3 = tf.layers.maxpool2d(h3, 3, 2, 'same')\n",
    "        h3 = tf.nn.dropout(h3, keep_prob) # Regularization\n",
    "        h3 = tf.maximum(h3*alpha, h3) # Leaky ReLu\n",
    "        h3 = tf.layers.batch_normalization(h3)\n",
    "        \n",
    "    with tf.name_scope(\"Hidden_Layer4\"):\n",
    "        h4 = tf.layers.conv1d(h3, h_dim*4, 10, 1, 'same', activation=None)\n",
    "        h4 = tf.nn.dropout(h4, keep_prob) # Regularization\n",
    "        h4 = tf.maximum(h4*alpha, h4) # Leaky ReLu\n",
    "        h4 = tf.layers.batch_normalization(h4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.name_scope(\"Output\"):\n",
    "        flat_dim = int(h4.get_shape()[1])*int(h4.get_shape()[2])\n",
    "        flat = tf.reshape(h4, [-1, flat_dim])\n",
    "        #print(\"flat: {}\".format(flat.shape))\n",
    "        logits = tf.layers.dense(flat, n_classes, activation=None, name='logits')\n",
    "        #print(\"logits: {}\".format(logits.shape))\n",
    "        #out = tf.nn.softmax(logits, name='softmax_out')\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Validation_Stats\"):\n",
    "        validation_loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "        validation_accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "        train_accuracy = session.run(accuracy, feed_dict={x: train_features[:1000], y: train_labels[:1000], keep_prob: 1.0})\n",
    "        print(\"Train Accuracy: {}, Validation Accuracy: {}, Validation Loss: {}\".format(train_accuracy, validation_accuracy, validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x, y, learn_rate, keep_prob = model_inputs(data_width, n_classes)\n",
    "\n",
    "#Model\n",
    "logits = network(x, keep_prob, n_classes)\n",
    "\n",
    "with tf.name_scope(\"Cost\"):\n",
    "    # Cost and Optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y, name='loss'), name='cost')\n",
    "    \n",
    "with tf.name_scope(\"Train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate, name='optimizer').minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1), name='prediction')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the graph for TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_writer = tf.summary.FileWriter('./logs/2', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 8\n",
    "keep_probability = 0.80\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy to beat (Min of 3 classes)\n",
    "print(\"{:.3}%\".format((1/n_classes)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0: Train Accuracy: 0.11100000143051147, Validation Accuracy: 0.12086330354213715, Validation Loss: 2.0788094997406006\n",
      "Epoch 1: Train Accuracy: 0.11100000143051147, Validation Accuracy: 0.12086330354213715, Validation Loss: 2.0759968757629395\n",
      "Epoch 2: Train Accuracy: 0.3009999990463257, Validation Accuracy: 0.2798561453819275, Validation Loss: 1.8462070226669312\n",
      "Epoch 3: Train Accuracy: 0.39800000190734863, Validation Accuracy: 0.3827338218688965, Validation Loss: 1.30994713306427\n",
      "Epoch 4: Train Accuracy: 0.48799997568130493, Validation Accuracy: 0.49280571937561035, Validation Loss: 1.0393019914627075\n",
      "Epoch 5: Train Accuracy: 0.5289999842643738, Validation Accuracy: 0.5251798629760742, Validation Loss: 0.8665015697479248\n",
      "Epoch 6: Train Accuracy: 0.5600000023841858, Validation Accuracy: 0.5482014417648315, Validation Loss: 0.8854858875274658\n",
      "Epoch 7: Train Accuracy: 0.5680000185966492, Validation Accuracy: 0.5532374382019043, Validation Loss: 0.7198375463485718\n",
      "Epoch 8: Train Accuracy: 0.5889999866485596, Validation Accuracy: 0.5726618766784668, Validation Loss: 0.7162207365036011\n",
      "Epoch 9: Train Accuracy: 0.6049999594688416, Validation Accuracy: 0.5784173011779785, Validation Loss: 0.6519940495491028\n",
      "Epoch 10: Train Accuracy: 0.6200000643730164, Validation Accuracy: 0.5906475186347961, Validation Loss: 0.6625261902809143\n",
      "Epoch 11: Train Accuracy: 0.6369999647140503, Validation Accuracy: 0.6122302412986755, Validation Loss: 0.5432682633399963\n",
      "Epoch 12: Train Accuracy: 0.659000039100647, Validation Accuracy: 0.6115108728408813, Validation Loss: 0.6448947787284851\n",
      "Epoch 13: Train Accuracy: 0.6599999666213989, Validation Accuracy: 0.6187050342559814, Validation Loss: 0.6169244050979614\n",
      "Epoch 14: Train Accuracy: 0.6809999942779541, Validation Accuracy: 0.6316547393798828, Validation Loss: 0.49568939208984375\n",
      "Epoch 15: Train Accuracy: 0.6930000185966492, Validation Accuracy: 0.632374107837677, Validation Loss: 0.47794097661972046\n",
      "Epoch 16: Train Accuracy: 0.6979999542236328, Validation Accuracy: 0.6489208340644836, Validation Loss: 0.4168347120285034\n",
      "Epoch 17: Train Accuracy: 0.7190000414848328, Validation Accuracy: 0.6467626094818115, Validation Loss: 0.5119682550430298\n",
      "Epoch 18: Train Accuracy: 0.7279999852180481, Validation Accuracy: 0.6539568305015564, Validation Loss: 0.4039073884487152\n",
      "Epoch 19: Train Accuracy: 0.7299999594688416, Validation Accuracy: 0.6568344831466675, Validation Loss: 0.27654892206192017\n",
      "Epoch 20: Train Accuracy: 0.7540000677108765, Validation Accuracy: 0.666906476020813, Validation Loss: 0.21167820692062378\n",
      "Epoch 21: Train Accuracy: 0.7610000967979431, Validation Accuracy: 0.6712230443954468, Validation Loss: 0.32462969422340393\n",
      "Epoch 22: Train Accuracy: 0.7630000114440918, Validation Accuracy: 0.6776978373527527, Validation Loss: 0.2878234088420868\n",
      "Epoch 23: Train Accuracy: 0.753000020980835, Validation Accuracy: 0.6733812689781189, Validation Loss: 0.19559288024902344\n",
      "Epoch 24: Train Accuracy: 0.7890000343322754, Validation Accuracy: 0.6870504021644592, Validation Loss: 0.1942913681268692\n",
      "Epoch 25: Train Accuracy: 0.7739999890327454, Validation Accuracy: 0.6697841882705688, Validation Loss: 0.1928727924823761\n",
      "Epoch 26: Train Accuracy: 0.7960000038146973, Validation Accuracy: 0.6856115460395813, Validation Loss: 0.1515953540802002\n",
      "Epoch 27: Train Accuracy: 0.8040000200271606, Validation Accuracy: 0.690647542476654, Validation Loss: 0.18870142102241516\n",
      "Epoch 28: Train Accuracy: 0.8090000748634338, Validation Accuracy: 0.691366970539093, Validation Loss: 0.29549044370651245\n",
      "Epoch 29: Train Accuracy: 0.8100000619888306, Validation Accuracy: 0.6892085671424866, Validation Loss: 0.1533258557319641\n",
      "Epoch 30: Train Accuracy: 0.8110000491142273, Validation Accuracy: 0.7014387845993042, Validation Loss: 0.14042435586452484\n",
      "Epoch 31: Train Accuracy: 0.8129999041557312, Validation Accuracy: 0.6906474232673645, Validation Loss: 0.14693446457386017\n",
      "Epoch 32: Train Accuracy: 0.8320000171661377, Validation Accuracy: 0.7086330652236938, Validation Loss: 0.1785474568605423\n",
      "Epoch 33: Train Accuracy: 0.8360000252723694, Validation Accuracy: 0.7050359845161438, Validation Loss: 0.1669735610485077\n",
      "Epoch 34: Train Accuracy: 0.8339999914169312, Validation Accuracy: 0.6978417038917542, Validation Loss: 0.0896926075220108\n",
      "Epoch 35: Train Accuracy: 0.8259999752044678, Validation Accuracy: 0.7028776407241821, Validation Loss: 0.09912195056676865\n",
      "Epoch 36: Train Accuracy: 0.8509999513626099, Validation Accuracy: 0.7107914090156555, Validation Loss: 0.13553336262702942\n",
      "Epoch 37: Train Accuracy: 0.8420000076293945, Validation Accuracy: 0.7165467739105225, Validation Loss: 0.07575146853923798\n",
      "Epoch 38: Train Accuracy: 0.8519999980926514, Validation Accuracy: 0.705755352973938, Validation Loss: 0.12444046139717102\n",
      "Epoch 39: Train Accuracy: 0.847000002861023, Validation Accuracy: 0.7129496335983276, Validation Loss: 0.09143811464309692\n",
      "Epoch 40: Train Accuracy: 0.8470000624656677, Validation Accuracy: 0.7122302055358887, Validation Loss: 0.061435963958501816\n",
      "Epoch 41: Train Accuracy: 0.8639999628067017, Validation Accuracy: 0.7071942090988159, Validation Loss: 0.08326331526041031\n",
      "Epoch 42: Train Accuracy: 0.8609999418258667, Validation Accuracy: 0.7100719213485718, Validation Loss: 0.07572997361421585\n",
      "Epoch 43: Train Accuracy: 0.843000054359436, Validation Accuracy: 0.6978417038917542, Validation Loss: 0.021698221564292908\n",
      "Epoch 44: Train Accuracy: 0.8530000448226929, Validation Accuracy: 0.7122302055358887, Validation Loss: 0.06433054059743881\n",
      "Epoch 45: Train Accuracy: 0.8750000596046448, Validation Accuracy: 0.7143884897232056, Validation Loss: 0.06267086416482925\n",
      "Epoch 46: Train Accuracy: 0.8870000839233398, Validation Accuracy: 0.7115107774734497, Validation Loss: 0.057935573160648346\n",
      "Epoch 47: Train Accuracy: 0.8810000419616699, Validation Accuracy: 0.7143884897232056, Validation Loss: 0.036723267287015915\n",
      "Epoch 48: Train Accuracy: 0.8810000419616699, Validation Accuracy: 0.7165467739105225, Validation Loss: 0.030319275334477425\n",
      "Epoch 49: Train Accuracy: 0.8880000114440918, Validation Accuracy: 0.7187050580978394, Validation Loss: 0.054226502776145935\n",
      "Epoch 50: Train Accuracy: 0.8790000081062317, Validation Accuracy: 0.7107913494110107, Validation Loss: 0.06342707574367523\n",
      "Epoch 51: Train Accuracy: 0.8960000276565552, Validation Accuracy: 0.7208632826805115, Validation Loss: 0.05597052350640297\n",
      "Epoch 52: Train Accuracy: 0.8780001401901245, Validation Accuracy: 0.7122301459312439, Validation Loss: 0.03778849542140961\n",
      "Epoch 53: Train Accuracy: 0.8819999694824219, Validation Accuracy: 0.7122301459312439, Validation Loss: 0.05812336876988411\n",
      "Epoch 54: Train Accuracy: 0.9089999794960022, Validation Accuracy: 0.7201438546180725, Validation Loss: 0.07786133885383606\n",
      "Epoch 55: Train Accuracy: 0.8830000162124634, Validation Accuracy: 0.7071942687034607, Validation Loss: 0.040198519825935364\n",
      "Epoch 56: Train Accuracy: 0.902999997138977, Validation Accuracy: 0.730215847492218, Validation Loss: 0.0493939071893692\n",
      "Epoch 57: Train Accuracy: 0.8910000324249268, Validation Accuracy: 0.7143884301185608, Validation Loss: 0.027684923261404037\n",
      "Epoch 58: Train Accuracy: 0.8939999341964722, Validation Accuracy: 0.7136690616607666, Validation Loss: 0.03687549754977226\n",
      "Epoch 59: Train Accuracy: 0.902999997138977, Validation Accuracy: 0.7280575633049011, Validation Loss: 0.019929219037294388\n",
      "Epoch 60: Train Accuracy: 0.9010000824928284, Validation Accuracy: 0.7237409949302673, Validation Loss: 0.03455163538455963\n",
      "Epoch 61: Train Accuracy: 0.9019999504089355, Validation Accuracy: 0.7165467143058777, Validation Loss: 0.023394864052534103\n",
      "Epoch 62: Train Accuracy: 0.9110000133514404, Validation Accuracy: 0.7122302055358887, Validation Loss: 0.022630203515291214\n",
      "Epoch 63: Train Accuracy: 0.9200000166893005, Validation Accuracy: 0.7129496335983276, Validation Loss: 0.05021245777606964\n",
      "Epoch 64: Train Accuracy: 0.9110000133514404, Validation Accuracy: 0.7158272862434387, Validation Loss: 0.01995275169610977\n",
      "Epoch 65: Train Accuracy: 0.918999969959259, Validation Accuracy: 0.7187050580978394, Validation Loss: 0.019146647304296494\n",
      "Epoch 66: Train Accuracy: 0.9179999828338623, Validation Accuracy: 0.7201438546180725, Validation Loss: 0.028776172548532486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Train Accuracy: 0.9229999780654907, Validation Accuracy: 0.7215827107429504, Validation Loss: 0.02108955755829811\n",
      "Epoch 68: Train Accuracy: 0.9180000424385071, Validation Accuracy: 0.7201438546180725, Validation Loss: 0.05029941722750664\n",
      "Epoch 69: Train Accuracy: 0.9180000424385071, Validation Accuracy: 0.7201438546180725, Validation Loss: 0.03517947345972061\n",
      "Epoch 70: Train Accuracy: 0.9239999651908875, Validation Accuracy: 0.7151079177856445, Validation Loss: 0.025195274502038956\n",
      "Epoch 71: Train Accuracy: 0.9230000376701355, Validation Accuracy: 0.7230215668678284, Validation Loss: 0.028114547953009605\n",
      "Epoch 72: Train Accuracy: 0.9220000505447388, Validation Accuracy: 0.7273381352424622, Validation Loss: 0.022327108308672905\n",
      "Epoch 73: Train Accuracy: 0.9169999957084656, Validation Accuracy: 0.7258992791175842, Validation Loss: 0.031027846038341522\n",
      "Epoch 74: Train Accuracy: 0.9280000329017639, Validation Accuracy: 0.7201438546180725, Validation Loss: 0.02005869522690773\n",
      "Epoch 75: Train Accuracy: 0.9420000910758972, Validation Accuracy: 0.7302157878875732, Validation Loss: 0.04355202615261078\n",
      "Epoch 76: Train Accuracy: 0.9279999732971191, Validation Accuracy: 0.7201438546180725, Validation Loss: 0.021135907620191574\n",
      "Epoch 77: Train Accuracy: 0.937000036239624, Validation Accuracy: 0.7381294965744019, Validation Loss: 0.1039341613650322\n",
      "Epoch 78: Train Accuracy: 0.9160000681877136, Validation Accuracy: 0.7136690616607666, Validation Loss: 0.026090970262885094\n",
      "Epoch 79: Train Accuracy: 0.9410001039505005, Validation Accuracy: 0.7309352159500122, Validation Loss: 0.07472773641347885\n",
      "Epoch 80: Train Accuracy: 0.9429999589920044, Validation Accuracy: 0.730935275554657, Validation Loss: 0.04957298934459686\n",
      "Epoch 81: Train Accuracy: 0.9300000071525574, Validation Accuracy: 0.7201439142227173, Validation Loss: 0.011874652467668056\n",
      "Epoch 82: Train Accuracy: 0.953000009059906, Validation Accuracy: 0.7388489842414856, Validation Loss: 0.016766764223575592\n",
      "Epoch 83: Train Accuracy: 0.9279999732971191, Validation Accuracy: 0.7194244265556335, Validation Loss: 0.012860691174864769\n",
      "Epoch 84: Train Accuracy: 0.9430000185966492, Validation Accuracy: 0.7395683526992798, Validation Loss: 0.03654221072793007\n",
      "Epoch 85: Train Accuracy: 0.9460000991821289, Validation Accuracy: 0.7287769913673401, Validation Loss: 0.008824004791676998\n",
      "Epoch 86: Train Accuracy: 0.9340000152587891, Validation Accuracy: 0.729496419429779, Validation Loss: 0.016895076259970665\n",
      "Epoch 87: Train Accuracy: 0.9470000863075256, Validation Accuracy: 0.730935275554657, Validation Loss: 0.05169110745191574\n",
      "Epoch 88: Train Accuracy: 0.9350000023841858, Validation Accuracy: 0.7266187071800232, Validation Loss: 0.022141482681035995\n",
      "Epoch 89: Train Accuracy: 0.9570000767707825, Validation Accuracy: 0.7208632826805115, Validation Loss: 0.05233814939856529\n",
      "Epoch 90: Train Accuracy: 0.9620000123977661, Validation Accuracy: 0.7251798510551453, Validation Loss: 0.036450546234846115\n",
      "Epoch 91: Train Accuracy: 0.956000030040741, Validation Accuracy: 0.7287769913673401, Validation Loss: 0.032888833433389664\n",
      "Epoch 92: Train Accuracy: 0.9500000476837158, Validation Accuracy: 0.7345324158668518, Validation Loss: 0.04524402320384979\n",
      "Epoch 93: Train Accuracy: 0.9629999995231628, Validation Accuracy: 0.7374100089073181, Validation Loss: 0.1433345526456833\n",
      "Epoch 94: Train Accuracy: 0.955000102519989, Validation Accuracy: 0.729496419429779, Validation Loss: 0.023794125765562057\n",
      "Epoch 95: Train Accuracy: 0.9580000042915344, Validation Accuracy: 0.7446042895317078, Validation Loss: 0.024018343538045883\n",
      "Epoch 96: Train Accuracy: 0.9550000429153442, Validation Accuracy: 0.7287769913673401, Validation Loss: 0.009289957582950592\n",
      "Epoch 97: Train Accuracy: 0.9580000638961792, Validation Accuracy: 0.730935275554657, Validation Loss: 0.014473111368715763\n",
      "Epoch 98: Train Accuracy: 0.9419999718666077, Validation Accuracy: 0.7251798510551453, Validation Loss: 0.01858130656182766\n",
      "Epoch 99: Train Accuracy: 0.9649999737739563, Validation Accuracy: 0.7374100685119629, Validation Loss: 0.024761872366070747\n",
      "Epoch 100: Train Accuracy: 0.9580000638961792, Validation Accuracy: 0.7366906404495239, Validation Loss: 0.04882200062274933\n",
      "Epoch 101: Train Accuracy: 0.9630000591278076, Validation Accuracy: 0.734532356262207, Validation Loss: 0.01174848061054945\n",
      "Epoch 102: Train Accuracy: 0.9500000476837158, Validation Accuracy: 0.7251797914505005, Validation Loss: 0.09759745746850967\n",
      "Epoch 103: Train Accuracy: 0.9690000414848328, Validation Accuracy: 0.7417266368865967, Validation Loss: 0.02752804383635521\n",
      "Epoch 104: Train Accuracy: 0.9660000801086426, Validation Accuracy: 0.735971212387085, Validation Loss: 0.01716095767915249\n",
      "Epoch 105: Train Accuracy: 0.9570000767707825, Validation Accuracy: 0.7374100685119629, Validation Loss: 0.0357731357216835\n",
      "Epoch 106: Train Accuracy: 0.9639999866485596, Validation Accuracy: 0.7424460053443909, Validation Loss: 0.054125577211380005\n",
      "Epoch 107: Train Accuracy: 0.9620000123977661, Validation Accuracy: 0.740287721157074, Validation Loss: 0.031273987144231796\n",
      "Epoch 108: Train Accuracy: 0.9650000333786011, Validation Accuracy: 0.7366907000541687, Validation Loss: 0.04762483015656471\n",
      "Epoch 109: Train Accuracy: 0.9649999737739563, Validation Accuracy: 0.7489208579063416, Validation Loss: 0.052306387573480606\n",
      "Epoch 110: Train Accuracy: 0.9709999561309814, Validation Accuracy: 0.7374101281166077, Validation Loss: 0.0446084663271904\n",
      "Epoch 111: Train Accuracy: 0.953000009059906, Validation Accuracy: 0.7287769913673401, Validation Loss: 0.015574383549392223\n",
      "Epoch 112: Train Accuracy: 0.9609999656677246, Validation Accuracy: 0.7330935597419739, Validation Loss: 0.014033250510692596\n",
      "Epoch 113: Train Accuracy: 0.9720000624656677, Validation Accuracy: 0.7381295561790466, Validation Loss: 0.014051107689738274\n",
      "Epoch 114: Train Accuracy: 0.9570000171661377, Validation Accuracy: 0.7338129878044128, Validation Loss: 0.054290492087602615\n",
      "Epoch 115: Train Accuracy: 0.9520000219345093, Validation Accuracy: 0.7474820017814636, Validation Loss: 0.008541813120245934\n",
      "Epoch 116: Train Accuracy: 0.972000002861023, Validation Accuracy: 0.7424460649490356, Validation Loss: 0.013658933341503143\n",
      "Epoch 117: Train Accuracy: 0.968000054359436, Validation Accuracy: 0.7482013702392578, Validation Loss: 0.006756093818694353\n",
      "Epoch 118: Train Accuracy: 0.9650000333786011, Validation Accuracy: 0.7532374858856201, Validation Loss: 0.01385335810482502\n",
      "Epoch 119: Train Accuracy: 0.9570000171661377, Validation Accuracy: 0.7438848614692688, Validation Loss: 0.01381625421345234\n",
      "Epoch 120: Train Accuracy: 0.9650000333786011, Validation Accuracy: 0.7438849210739136, Validation Loss: 0.03895074874162674\n",
      "Epoch 121: Train Accuracy: 0.9760000109672546, Validation Accuracy: 0.7510790824890137, Validation Loss: 0.02170422300696373\n",
      "Epoch 122: Train Accuracy: 0.9700000882148743, Validation Accuracy: 0.7489208579063416, Validation Loss: 0.023805592209100723\n",
      "Epoch 123: Train Accuracy: 0.9750000834465027, Validation Accuracy: 0.7402878403663635, Validation Loss: 0.04490353539586067\n",
      "Epoch 124: Train Accuracy: 0.9649999737739563, Validation Accuracy: 0.7388489842414856, Validation Loss: 0.007894336245954037\n",
      "Epoch 125: Train Accuracy: 0.9730000495910645, Validation Accuracy: 0.7446043491363525, Validation Loss: 0.023080255836248398\n",
      "Epoch 126: Train Accuracy: 0.9789999127388, Validation Accuracy: 0.7453237175941467, Validation Loss: 0.03348936513066292\n",
      "Epoch 127: Train Accuracy: 0.9670000672340393, Validation Accuracy: 0.7438848614692688, Validation Loss: 0.020610054954886436\n",
      "Epoch 128: Train Accuracy: 0.9729999899864197, Validation Accuracy: 0.7374100089073181, Validation Loss: 0.014430643059313297\n",
      "Epoch 129: Train Accuracy: 0.9729999899864197, Validation Accuracy: 0.734532356262207, Validation Loss: 0.026030344888567924\n",
      "Epoch 130: Train Accuracy: 0.9760000109672546, Validation Accuracy: 0.7431654930114746, Validation Loss: 0.010335423983633518\n",
      "Epoch 131: Train Accuracy: 0.9779999852180481, Validation Accuracy: 0.7510790824890137, Validation Loss: 0.01294681429862976\n",
      "Epoch 132: Train Accuracy: 0.9690001010894775, Validation Accuracy: 0.7446043491363525, Validation Loss: 0.0125746363773942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: Train Accuracy: 0.9790000915527344, Validation Accuracy: 0.7381295561790466, Validation Loss: 0.11133968830108643\n",
      "Epoch 134: Train Accuracy: 0.9779999852180481, Validation Accuracy: 0.7330935597419739, Validation Loss: 0.03806617110967636\n",
      "Epoch 135: Train Accuracy: 0.9760000109672546, Validation Accuracy: 0.7460431456565857, Validation Loss: 0.006760152522474527\n",
      "Epoch 136: Train Accuracy: 0.9740000367164612, Validation Accuracy: 0.7489208579063416, Validation Loss: 0.01501463819295168\n",
      "Epoch 137: Train Accuracy: 0.9779999852180481, Validation Accuracy: 0.7532373666763306, Validation Loss: 0.04385601729154587\n",
      "Epoch 138: Train Accuracy: 0.9819999933242798, Validation Accuracy: 0.7453237771987915, Validation Loss: 0.07641462236642838\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-1582e972384e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                                            \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                            \u001b[0mlearn_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                            keep_prob: keep_probability})\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {}: '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfgpu1.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_model_path = './key_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in get_batches(train_features, train_labels, batch_size):\n",
    "            sess.run(optimizer, feed_dict={x: batch_features, \n",
    "                                           y: batch_labels, \n",
    "                                           learn_rate: learning_rate, \n",
    "                                           keep_prob: keep_probability})\n",
    "        if epoch % 1 == 0:\n",
    "            print('Epoch {}: '.format(epoch), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)         \n",
    "            \n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as sess:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
